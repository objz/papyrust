This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
shaders/
  plasma.frag
  rainbow.frag
src/
  bin/
    daemon/
      shaders/
        bicubic.wgsl
        fsr.wgsl
        lanczos.wgsl
        mitchell.wgsl
      wayland/
        fifo.rs
        mod.rs
        monitors.rs
        renderer.rs
        state.rs
      ipc.rs
      lossless_scaling.rs
      main.rs
      media.rs
      utils.rs
    cli.rs
  ui/
    components/
      lib_popup.rs
      mod.rs
      panel.rs
    loader/
      mod.rs
      project.rs
    pages/
      discover.rs
      library.rs
      mod.rs
    ipc.rs
    mod.rs
    state.rs
    view.rs
  main.rs
.gitignore
build.rs
Cargo.toml
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/bin/daemon/shaders/bicubic.wgsl">
// Bicubic interpolation
fn cubic(t: f32) -> f32 {
    let a = -0.5;
    let t2 = t * t;
    let t3 = t2 * t;
    
    if t <= 1.0 {
        return (a + 2.0) * t3 - (a + 3.0) * t2 + 1.0;
    } else if t <= 2.0 {
        return a * t3 - 5.0 * a * t2 + 8.0 * a * t - 4.0 * a;
    } else {
        return 0.0;
    }
}

@fragment
fn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {
    let tex_coords = input.tex_coords;
    let scaled_coords = tex_coords * uniforms.input_size;
    let base_coords = floor(scaled_coords - 0.5) + 0.5;
    let f = scaled_coords - base_coords;
    
    var result = vec4<f32>(0.0);
    
    // 4x4 bicubic kernel
    for (var i = -1; i <= 2; i++) {
        for (var j = -1; j <= 2; j++) {
            let sample_coords = (base_coords + vec2<f32>(f32(i), f32(j))) / uniforms.input_size;
            let weight_x = cubic(abs(f32(i) - f.x));
            let weight_y = cubic(abs(f32(j) - f.y));
            let weight = weight_x * weight_y;
            
            if sample_coords.x >= 0.0 && sample_coords.x <= 1.0 && 
               sample_coords.y >= 0.0 && sample_coords.y <= 1.0 {
                result += textureSample(input_texture, texture_sampler, sample_coords) * weight;
            }
        }
    }
    
    return clamp(result, vec4<f32>(0.0), vec4<f32>(1.0));
}
</file>

<file path="src/bin/daemon/shaders/fsr.wgsl">
@fragment
fn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {
    let tex_coords = input.tex_coords;
    let texel_size = 1.0 / uniforms.input_size;
    
    // FSR EASU (Edge Adaptive Spatial Upsampling)
    let b = textureSample(input_texture, texture_sampler, tex_coords + vec2<f32>(-texel_size.x, -texel_size.y));
    let d = textureSample(input_texture, texture_sampler, tex_coords + vec2<f32>(0.0, -texel_size.y));
    let f = textureSample(input_texture, texture_sampler, tex_coords + vec2<f32>(texel_size.x, -texel_size.y));
    let h = textureSample(input_texture, texture_sampler, tex_coords + vec2<f32>(-texel_size.x, 0.0));
    let i = textureSample(input_texture, texture_sampler, tex_coords);
    let j = textureSample(input_texture, texture_sampler, tex_coords + vec2<f32>(texel_size.x, 0.0));
    let l = textureSample(input_texture, texture_sampler, tex_coords + vec2<f32>(-texel_size.x, texel_size.y));
    let n = textureSample(input_texture, texture_sampler, tex_coords + vec2<f32>(0.0, texel_size.y));
    let p = textureSample(input_texture, texture_sampler, tex_coords + vec2<f32>(texel_size.x, texel_size.y));
    
    // Calculate local contrast
    let min_g = min(min(min(d.g, h.g), min(i.g, j.g)), n.g);
    let max_g = max(max(max(d.g, h.g), max(i.g, j.g)), n.g);
    
    // Edge detection
    let w = 1.0 - saturate((max_g - min_g) / max(max_g, 1e-6));
    
    // Directional filtering
    let dir_horizontal = abs(h.g + j.g - 2.0 * i.g);
    let dir_vertical = abs(d.g + n.g - 2.0 * i.g);
    
    var result: vec4<f32>;
    if dir_horizontal < dir_vertical {
        // Horizontal edge - interpolate vertically
        result = mix(d, n, 0.5);
    } else {
        // Vertical edge - interpolate horizontally  
        result = mix(h, j, 0.5);
    }
    
    // Apply sharpening
    let sharpened = i + (i - result) * uniforms.sharpening * w;
    
    return mix(i, sharpened, w);
}
</file>

<file path="src/bin/daemon/shaders/lanczos.wgsl">
// High-quality Lanczos scaling
fn lanczos(x: f32) -> f32 {
    if abs(x) < 1e-6 {
        return 1.0;
    }
    if abs(x) >= 3.0 {
        return 0.0;
    }
    let pi_x = 3.14159265359 * x;
    return 3.0 * sin(pi_x) * sin(pi_x / 3.0) / (pi_x * pi_x);
}

@fragment
fn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {
    let tex_coords = input.tex_coords;
    let scaled_coords = tex_coords * uniforms.input_size;
    let base_coords = floor(scaled_coords - 0.5) + 0.5;
    let f = scaled_coords - base_coords;
    
    var result = vec4<f32>(0.0);
    var weight_sum = 0.0;
    
    // 6x6 Lanczos kernel
    for (var i = -2; i <= 3; i++) {
        for (var j = -2; j <= 3; j++) {
            let sample_coords = (base_coords + vec2<f32>(f32(i), f32(j))) / uniforms.input_size;
            let weight_x = lanczos(f32(i) - f.x);
            let weight_y = lanczos(f32(j) - f.y);
            let weight = weight_x * weight_y;
            
            if sample_coords.x >= 0.0 && sample_coords.x <= 1.0 && 
               sample_coords.y >= 0.0 && sample_coords.y <= 1.0 {
                result += textureSample(input_texture, texture_sampler, sample_coords) * weight;
                weight_sum += weight;
            }
        }
    }
    
    if weight_sum > 0.0 {
        result /= weight_sum;
    }
    
    // Apply sharpening
    let center = textureSample(input_texture, texture_sampler, tex_coords);
    let sharpened = result + (result - center) * uniforms.sharpening;
    
    return clamp(sharpened, vec4<f32>(0.0), vec4<f32>(1.0));
}
</file>

<file path="src/bin/daemon/shaders/mitchell.wgsl">
// Mitchell-Netravali cubic filter
fn mitchell(x: f32) -> f32 {
    let b = 1.0 / 3.0;
    let c = 1.0 / 3.0;
    let ax = abs(x);
    
    if ax < 1.0 {
        return ((12.0 - 9.0 * b - 6.0 * c) * ax * ax * ax + 
                (-18.0 + 12.0 * b + 6.0 * c) * ax * ax + 
                (6.0 - 2.0 * b)) / 6.0;
    } else if ax < 2.0 {
        return ((-b - 6.0 * c) * ax * ax * ax + 
                (6.0 * b + 30.0 * c) * ax * ax + 
                (-12.0 * b - 48.0 * c) * ax + 
                (8.0 * b + 24.0 * c)) / 6.0;
    } else {
        return 0.0;
    }
}

@fragment
fn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {
    let tex_coords = input.tex_coords;
    let scaled_coords = tex_coords * uniforms.input_size;
    let base_coords = floor(scaled_coords - 0.5) + 0.5;
    let f = scaled_coords - base_coords;
    
    var result = vec4<f32>(0.0);
    var weight_sum = 0.0;
    
    // 4x4 Mitchell kernel
    for (var i = -1; i <= 2; i++) {
        for (var j = -1; j <= 2; j++) {
            let sample_coords = (base_coords + vec2<f32>(f32(i), f32(j))) / uniforms.input_size;
            let weight_x = mitchell(f32(i) - f.x);
            let weight_y = mitchell(f32(j) - f.y);
            let weight = weight_x * weight_y;
            
            if sample_coords.x >= 0.0 && sample_coords.x <= 1.0 && 
               sample_coords.y >= 0.0 && sample_coords.y <= 1.0 {
                result += textureSample(input_texture, texture_sampler, sample_coords) * weight;
                weight_sum += weight;
            }
        }
    }
    
    if weight_sum > 0.0 {
        result /= weight_sum;
    }
    
    return clamp(result, vec4<f32>(0.0), vec4<f32>(1.0));
}
</file>

<file path="src/bin/daemon/lossless_scaling.rs">
use anyhow::{Result, anyhow};
use bytemuck::{Pod, Zeroable};
use std::borrow::Cow;
use wgpu::util::DeviceExt;

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
#[allow(dead_code)]
struct Vertex {
    position: [f32; 2],
    tex_coords: [f32; 2],
}

impl Vertex {
    #[allow(dead_code)]
    fn desc<'a>() -> wgpu::VertexBufferLayout<'a> {
        wgpu::VertexBufferLayout {
            array_stride: std::mem::size_of::<Vertex>() as wgpu::BufferAddress,
            step_mode: wgpu::VertexStepMode::Vertex,
            attributes: &[
                wgpu::VertexAttribute {
                    offset: 0,
                    shader_location: 0,
                    format: wgpu::VertexFormat::Float32x2,
                },
                wgpu::VertexAttribute {
                    offset: std::mem::size_of::<[f32; 2]>() as wgpu::BufferAddress,
                    shader_location: 1,
                    format: wgpu::VertexFormat::Float32x2,
                },
            ],
        }
    }
}

#[allow(dead_code)]
const VERTICES: &[Vertex] = &[
    Vertex { position: [-1.0, 1.0], tex_coords: [0.0, 0.0] },   // Top-left
    Vertex { position: [-1.0, -1.0], tex_coords: [0.0, 1.0] },  // Bottom-left
    Vertex { position: [1.0, -1.0], tex_coords: [1.0, 1.0] },   // Bottom-right
    Vertex { position: [1.0, 1.0], tex_coords: [1.0, 0.0] },    // Top-right
];

#[allow(dead_code)]
const INDICES: &[u16] = &[0, 1, 2, 2, 3, 0];

#[derive(Debug, Clone, Copy)]
pub enum ScalingAlgorithm {
    FSR,        // FidelityFX Super Resolution
    Lanczos,    // High-quality Lanczos
    Mitchell,   // Mitchell-Netravali filter
    Bicubic,    // Bicubic interpolation
}

#[allow(dead_code)]
pub struct LosslessScaler {
    device: wgpu::Device,
    queue: wgpu::Queue,
    render_pipeline: wgpu::RenderPipeline,
    vertex_buffer: wgpu::Buffer,
    index_buffer: wgpu::Buffer,
    bind_group_layout: wgpu::BindGroupLayout,
    sampler: wgpu::Sampler,
    uniform_buffer: wgpu::Buffer,
    algorithm: ScalingAlgorithm,
}

#[repr(C)]
#[derive(Debug, Copy, Clone, Pod, Zeroable)]
#[allow(dead_code)]
struct ScalingUniforms {
    input_size: [f32; 2],
    output_size: [f32; 2],
    scale_factor: f32,
    algorithm_type: u32,
    sharpening: f32,
    _padding: f32,
}

impl LosslessScaler {
    #[allow(dead_code)]
    pub async fn new(algorithm: ScalingAlgorithm) -> Result<Self> {
        tracing::info!(event = "lossless_scaler_init", ?algorithm, "Initializing lossless scaler");

        let instance = wgpu::Instance::new(wgpu::InstanceDescriptor {
            backends: wgpu::Backends::all(),
            ..Default::default()
        });

        let adapter = instance
            .request_adapter(&wgpu::RequestAdapterOptions {
                power_preference: wgpu::PowerPreference::HighPerformance,
                compatible_surface: None,
                force_fallback_adapter: false,
            })
            .await
            .ok_or_else(|| anyhow!("Failed to find suitable adapter"))?;

        let (device, queue) = adapter
            .request_device(
                &wgpu::DeviceDescriptor {
                    required_features: wgpu::Features::empty(),
                    required_limits: wgpu::Limits::default(),
                    label: None,
                },
                None,
            )
            .await
            .map_err(|e| anyhow!("Failed to create device: {}", e))?;

        let shader_source = Self::get_shader_source(algorithm);
        let shader = device.create_shader_module(wgpu::ShaderModuleDescriptor {
            label: Some("Lossless Scaling Shader"),
            source: wgpu::ShaderSource::Wgsl(Cow::Borrowed(&shader_source)),
        });

        let bind_group_layout = device.create_bind_group_layout(&wgpu::BindGroupLayoutDescriptor {
            entries: &[
                wgpu::BindGroupLayoutEntry {
                    binding: 0,
                    visibility: wgpu::ShaderStages::FRAGMENT,
                    ty: wgpu::BindingType::Texture {
                        multisampled: false,
                        view_dimension: wgpu::TextureViewDimension::D2,
                        sample_type: wgpu::TextureSampleType::Float { filterable: true },
                    },
                    count: None,
                },
                wgpu::BindGroupLayoutEntry {
                    binding: 1,
                    visibility: wgpu::ShaderStages::FRAGMENT,
                    ty: wgpu::BindingType::Sampler(wgpu::SamplerBindingType::Filtering),
                    count: None,
                },
                wgpu::BindGroupLayoutEntry {
                    binding: 2,
                    visibility: wgpu::ShaderStages::FRAGMENT,
                    ty: wgpu::BindingType::Buffer {
                        ty: wgpu::BufferBindingType::Uniform,
                        has_dynamic_offset: false,
                        min_binding_size: None,
                    },
                    count: None,
                },
            ],
            label: Some("Lossless Scaling Bind Group Layout"),
        });

        let render_pipeline_layout = device.create_pipeline_layout(&wgpu::PipelineLayoutDescriptor {
            label: Some("Lossless Scaling Pipeline Layout"),
            bind_group_layouts: &[&bind_group_layout],
            push_constant_ranges: &[],
        });

        let render_pipeline = device.create_render_pipeline(&wgpu::RenderPipelineDescriptor {
            label: Some("Lossless Scaling Pipeline"),
            layout: Some(&render_pipeline_layout),
            vertex: wgpu::VertexState {
                module: &shader,
                entry_point: "vs_main",
                buffers: &[Vertex::desc()],
                compilation_options: wgpu::PipelineCompilationOptions::default(),
            },
            fragment: Some(wgpu::FragmentState {
                module: &shader,
                entry_point: "fs_main",
                targets: &[Some(wgpu::ColorTargetState {
                    format: wgpu::TextureFormat::Rgba8UnormSrgb,
                    blend: Some(wgpu::BlendState::REPLACE),
                    write_mask: wgpu::ColorWrites::ALL,
                })],
                compilation_options: wgpu::PipelineCompilationOptions::default(),
            }),
            primitive: wgpu::PrimitiveState {
                topology: wgpu::PrimitiveTopology::TriangleList,
                strip_index_format: None,
                front_face: wgpu::FrontFace::Ccw,
                cull_mode: Some(wgpu::Face::Back),
                polygon_mode: wgpu::PolygonMode::Fill,
                unclipped_depth: false,
                conservative: false,
            },
            depth_stencil: None,
            multisample: wgpu::MultisampleState {
                count: 1,
                mask: !0,
                alpha_to_coverage_enabled: false,
            },
            multiview: None,
        });

        let vertex_buffer = device.create_buffer_init(&wgpu::util::BufferInitDescriptor {
            label: Some("Vertex Buffer"),
            contents: bytemuck::cast_slice(VERTICES),
            usage: wgpu::BufferUsages::VERTEX,
        });

        let index_buffer = device.create_buffer_init(&wgpu::util::BufferInitDescriptor {
            label: Some("Index Buffer"),
            contents: bytemuck::cast_slice(INDICES),
            usage: wgpu::BufferUsages::INDEX,
        });

        let sampler = device.create_sampler(&wgpu::SamplerDescriptor {
            address_mode_u: wgpu::AddressMode::ClampToEdge,
            address_mode_v: wgpu::AddressMode::ClampToEdge,
            address_mode_w: wgpu::AddressMode::ClampToEdge,
            mag_filter: wgpu::FilterMode::Linear,
            min_filter: wgpu::FilterMode::Linear,
            mipmap_filter: wgpu::FilterMode::Linear,
            ..Default::default()
        });

        let uniform_buffer = device.create_buffer(&wgpu::BufferDescriptor {
            label: Some("Scaling Uniforms"),
            size: std::mem::size_of::<ScalingUniforms>() as u64,
            usage: wgpu::BufferUsages::UNIFORM | wgpu::BufferUsages::COPY_DST,
            mapped_at_creation: false,
        });

        tracing::info!(event = "lossless_scaler_ready", ?algorithm, "Lossless scaler initialized");

        Ok(Self {
            device,
            queue,
            render_pipeline,
            vertex_buffer,
            index_buffer,
            bind_group_layout,
            sampler,
            uniform_buffer,
            algorithm,
        })
    }

    #[allow(dead_code)]
    pub fn scale_texture(
        &self,
        input_data: &[u8],
        input_width: u32,
        input_height: u32,
        output_width: u32,
        output_height: u32,
        sharpening: f32,
    ) -> Result<Vec<u8>> {
        let input_texture = self.device.create_texture(&wgpu::TextureDescriptor {
            label: Some("Input Texture"),
            size: wgpu::Extent3d {
                width: input_width,
                height: input_height,
                depth_or_array_layers: 1,
            },
            mip_level_count: 1,
            sample_count: 1,
            dimension: wgpu::TextureDimension::D2,
            format: wgpu::TextureFormat::Rgba8UnormSrgb,
            usage: wgpu::TextureUsages::TEXTURE_BINDING | wgpu::TextureUsages::COPY_DST,
            view_formats: &[],
        });

        self.queue.write_texture(
            wgpu::ImageCopyTexture {
                texture: &input_texture,
                mip_level: 0,
                origin: wgpu::Origin3d::ZERO,
                aspect: wgpu::TextureAspect::All,
            },
            input_data,
            wgpu::ImageDataLayout {
                offset: 0,
                bytes_per_row: Some(4 * input_width),
                rows_per_image: Some(input_height),
            },
            wgpu::Extent3d {
                width: input_width,
                height: input_height,
                depth_or_array_layers: 1,
            },
        );

        let output_texture = self.device.create_texture(&wgpu::TextureDescriptor {
            label: Some("Output Texture"),
            size: wgpu::Extent3d {
                width: output_width,
                height: output_height,
                depth_or_array_layers: 1,
            },
            mip_level_count: 1,
            sample_count: 1,
            dimension: wgpu::TextureDimension::D2,
            format: wgpu::TextureFormat::Rgba8UnormSrgb,
            usage: wgpu::TextureUsages::RENDER_ATTACHMENT | wgpu::TextureUsages::COPY_SRC,
            view_formats: &[],
        });

        let input_view = input_texture.create_view(&wgpu::TextureViewDescriptor::default());
        let output_view = output_texture.create_view(&wgpu::TextureViewDescriptor::default());

        let scale_factor = (output_width as f32 / input_width as f32).max(output_height as f32 / input_height as f32);

        let uniforms = ScalingUniforms {
            input_size: [input_width as f32, input_height as f32],
            output_size: [output_width as f32, output_height as f32],
            scale_factor,
            algorithm_type: self.algorithm as u32,
            sharpening,
            _padding: 0.0,
        };

        self.queue.write_buffer(&self.uniform_buffer, 0, bytemuck::cast_slice(&[uniforms]));

        let bind_group = self.device.create_bind_group(&wgpu::BindGroupDescriptor {
            layout: &self.bind_group_layout,
            entries: &[
                wgpu::BindGroupEntry {
                    binding: 0,
                    resource: wgpu::BindingResource::TextureView(&input_view),
                },
                wgpu::BindGroupEntry {
                    binding: 1,
                    resource: wgpu::BindingResource::Sampler(&self.sampler),
                },
                wgpu::BindGroupEntry {
                    binding: 2,
                    resource: self.uniform_buffer.as_entire_binding(),
                },
            ],
            label: Some("Scaling Bind Group"),
        });

        let mut encoder = self.device.create_command_encoder(&wgpu::CommandEncoderDescriptor {
            label: Some("Scaling Encoder"),
        });

        {
            let mut render_pass = encoder.begin_render_pass(&wgpu::RenderPassDescriptor {
                label: Some("Scaling Render Pass"),
                color_attachments: &[Some(wgpu::RenderPassColorAttachment {
                    view: &output_view,
                    resolve_target: None,
                    ops: wgpu::Operations {
                        load: wgpu::LoadOp::Clear(wgpu::Color::BLACK),
                        store: wgpu::StoreOp::Store,
                    },
                })],
                depth_stencil_attachment: None,
                timestamp_writes: None,
                occlusion_query_set: None,
            });

            render_pass.set_pipeline(&self.render_pipeline);
            render_pass.set_bind_group(0, &bind_group, &[]);
            render_pass.set_vertex_buffer(0, self.vertex_buffer.slice(..));
            render_pass.set_index_buffer(self.index_buffer.slice(..), wgpu::IndexFormat::Uint16);
            render_pass.draw_indexed(0..INDICES.len() as u32, 0, 0..1);
        }

        let buffer_size = (output_width * output_height * 4) as u64;
        let output_buffer = self.device.create_buffer(&wgpu::BufferDescriptor {
            label: Some("Output Buffer"),
            size: buffer_size,
            usage: wgpu::BufferUsages::COPY_DST | wgpu::BufferUsages::MAP_READ,
            mapped_at_creation: false,
        });

        encoder.copy_texture_to_buffer(
            wgpu::ImageCopyTexture {
                texture: &output_texture,
                mip_level: 0,
                origin: wgpu::Origin3d::ZERO,
                aspect: wgpu::TextureAspect::All,
            },
            wgpu::ImageCopyBuffer {
                buffer: &output_buffer,
                layout: wgpu::ImageDataLayout {
                    offset: 0,
                    bytes_per_row: Some(4 * output_width),
                    rows_per_image: Some(output_height),
                },
            },
            wgpu::Extent3d {
                width: output_width,
                height: output_height,
                depth_or_array_layers: 1,
            },
        );

        self.queue.submit(std::iter::once(encoder.finish()));

        let buffer_slice = output_buffer.slice(..);
        buffer_slice.map_async(wgpu::MapMode::Read, |_| {});
        self.device.poll(wgpu::Maintain::Wait);

        let data = buffer_slice.get_mapped_range();
        let result = data.to_vec();
        drop(data);
        output_buffer.unmap();

        tracing::debug!(
            event = "texture_scaled",
            algorithm = ?self.algorithm,
            input_size = format!("{}x{}", input_width, input_height),
            output_size = format!("{}x{}", output_width, output_height),
            scale_factor,
            sharpening,
            "Texture scaled with lossless algorithm"
        );

        Ok(result)
    }

    #[allow(dead_code)]
    fn get_shader_source(algorithm: ScalingAlgorithm) -> String {
        let algorithm_specific = match algorithm {
            ScalingAlgorithm::FSR => include_str!("shaders/fsr.wgsl"),
            ScalingAlgorithm::Lanczos => include_str!("shaders/lanczos.wgsl"),
            ScalingAlgorithm::Mitchell => include_str!("shaders/mitchell.wgsl"),
            ScalingAlgorithm::Bicubic => include_str!("shaders/bicubic.wgsl"),
        };

        format!(
            r#"
struct VertexInput {{
    @location(0) position: vec2<f32>,
    @location(1) tex_coords: vec2<f32>,
}}

struct VertexOutput {{
    @builtin(position) clip_position: vec4<f32>,
    @location(0) tex_coords: vec2<f32>,
}}

struct ScalingUniforms {{
    input_size: vec2<f32>,
    output_size: vec2<f32>,
    scale_factor: f32,
    algorithm_type: u32,
    sharpening: f32,
    _padding: f32,
}}

@group(0) @binding(0)
var input_texture: texture_2d<f32>;

@group(0) @binding(1)
var texture_sampler: sampler;

@group(0) @binding(2)
var<uniform> uniforms: ScalingUniforms;

@vertex
fn vs_main(input: VertexInput) -> VertexOutput {{
    var output: VertexOutput;
    output.clip_position = vec4<f32>(input.position, 0.0, 1.0);
    output.tex_coords = input.tex_coords;
    return output;
}}

{algorithm_specific}
"#
        )
    }
}
</file>

<file path="shaders/plasma.frag">
#ifdef GL_ES
precision mediump float;
#endif

uniform float time;
uniform vec2 resolution;
varying vec2 texCoords;

void main() {
    vec2 uv = texCoords;
    vec2 p = (uv - 0.5) * vec2(resolution.x/resolution.y, 1.0) * 2.0;

    float v1 = sin(p.x * 3.0 + time);
    float v2 = sin((p.x * cos(time*0.7) + p.y * sin(time*0.3)) * 4.0);
    float v3 = sin(length(p) * 5.0 - time * 1.5);

    float v = (v1 + v2 + v3) / 3.0;

    vec3 col = vec3(
        0.5 + 0.5 * sin(3.0 + v * 3.0),
        0.5 + 0.5 * sin(1.0 + v * 3.0),
        0.5 + 0.5 * sin(5.0 + v * 3.0)
    );

    gl_FragColor = vec4(col, 1.0);
}
</file>

<file path="shaders/rainbow.frag">
#version 100
precision mediump float;

uniform float time;
uniform vec2 resolution;

void main() {
    vec2 uv = gl_FragCoord.xy / resolution;

    float wave = 0.5 + 0.5 * sin(uv.x * 10.0 + time);

    gl_FragColor = vec4(uv.x, uv.y, wave, 1.0);
}
</file>

<file path="src/bin/daemon/wayland/fifo.rs">
use anyhow::{anyhow, Result};
use std::os::unix::io::{AsRawFd, RawFd};



const N_SAMPLES: usize = 44100 / 25;

#[derive(Debug)]
pub struct StereoSample {
    pub left: Vec<i16>,
    pub right: Vec<i16>,
}

impl StereoSample {
    fn new() -> Self {
        Self {
            left: vec![0; N_SAMPLES],
            right: vec![0; N_SAMPLES],
        }
    }
}


pub struct FifoReader {
    pub fd: RawFd,
}

impl FifoReader {
    pub fn new(fifo_path: &str) -> Result<Self> {
        use std::os::unix::fs::OpenOptionsExt;
        let file = std::fs::OpenOptions::new()
            .read(true)
            .custom_flags(libc::O_NONBLOCK)
            .open(fifo_path)?;

        Ok(Self {
            fd: file.as_raw_fd(),
        })
    }

    pub fn read_sample(&mut self) -> Result<Option<StereoSample>> {
        let mut buffer = vec![0u8; N_SAMPLES * 4];

        let bytes_read = unsafe {
            libc::read(
                self.fd,
                buffer.as_mut_ptr() as *mut libc::c_void,
                buffer.len(),
            )
        };

        if bytes_read < 0 {
            let errno = unsafe { *libc::__errno_location() };
            if errno == libc::EAGAIN || errno == libc::EWOULDBLOCK {
                return Ok(None);
            }
            return Err(anyhow!("Failed to read from FIFO: {}", errno));
        }

        if bytes_read == 0 {
            return Ok(None);
        }

        let samples_read = bytes_read as usize / 4;
        let mut stereo = StereoSample::new();

        for i in 0..samples_read.min(N_SAMPLES / 2) {
            let base = i * 4;
            if base + 3 < buffer.len() {
                stereo.left[i] = i16::from_le_bytes([buffer[base], buffer[base + 1]]);
                stereo.right[i] = i16::from_le_bytes([buffer[base + 2], buffer[base + 3]]);
            }
        }

        Ok(Some(stereo))
    }
}
</file>

<file path="src/ui/components/lib_popup.rs">
use iced::{
    alignment::{Horizontal, Vertical},
    widget::{button, mouse_area, text, Button, Column, Container, Row, Space},
    Background, Border, Color, Element, Length, Padding, Shadow, Vector,
};
use iced_video_player::VideoPlayer;

use crate::{ui::loader::project::Project, Message, Papyrust};

pub fn build<'a>(app: &'a Papyrust, project: &'a Project) -> Element<'a, Message> {
    let title = project.meta.title.as_deref().unwrap_or("Untitled");

    let video_preview = create_preview(app, project);

    let close_button = Button::new(text("Close").size(16))
        .on_press(Message::ClosePopup)
        .padding(Padding::from([8, 12]))
        .style(|_theme, status| {
            let base = Color::from_rgba(0.2, 0.2, 0.2, 0.8);
            let hover = Color::from_rgba(0.3, 0.3, 0.3, 0.9);
            let border_color = Color::from_rgba(0.6, 0.6, 0.6, 0.5);

            button::Style {
                background: Some(Background::Color(
                    if matches!(status, iced::widget::button::Status::Hovered) {
                        hover
                    } else {
                        base
                    },
                )),
                border: Border {
                    radius: 8.0.into(),
                    width: 1.0,
                    color: border_color,
                },
                text_color: Color::WHITE,
                ..Default::default()
            }
        });

    let apply_button = Button::new(text("Apply").size(16))
        .padding(Padding::from([8, 12]))
        .on_press(Message::ApplyProject(project.clone()))
        .style(|_theme, status| {
            let base = Color::from_rgba(0.2, 0.2, 0.2, 0.8);
            let hover = Color::from_rgba(0.3, 0.3, 0.3, 0.9);
            let border_color = Color::from_rgba(0.6, 0.6, 0.6, 0.5);

            button::Style {
                background: Some(Background::Color(
                    if matches!(status, iced::widget::button::Status::Hovered) {
                        hover
                    } else {
                        base
                    },
                )),
                border: Border {
                    radius: 8.0.into(),
                    width: 1.0,
                    color: border_color,
                },
                text_color: Color::WHITE,
                ..Default::default()
            }
        });

    let header = Row::new()
        .push(
            text(title)
                .size(24)
                .style(|_theme| iced::widget::text::Style {
                    color: Some(Color::WHITE),
                    ..Default::default()
                }),
        )
        .align_y(Vertical::Center);

    let footer_row = Row::new().spacing(10).push(close_button).push(apply_button);

    let footer = Container::new(footer_row)
        .align_x(Horizontal::Center)
        .width(Length::Fill);

    let popup_content = Column::new()
        .push(header)
        .push(video_preview)
        .push(Space::new(Length::Fill, Length::Fill))
        .push(footer)
        .spacing(20)
        .padding(20)
        .width(Length::Fill)
        .align_x(Horizontal::Center);

    let popup = Container::new(popup_content)
        .width(Length::Fixed(800.0))
        .height(Length::Fixed(600.0))
        .style(|_theme| iced::widget::container::Style {
            background: Some(Background::Color(Color::from_rgba(0.05, 0.05, 0.05, 0.98))),
            border: Border {
                radius: 16.0.into(),
                width: 2.0,
                color: Color::from_rgba(0.6, 0.6, 0.6, 0.4),
            },
            shadow: Shadow {
                color: Color::from_rgba(0.0, 0.0, 0.0, 0.5),
                offset: Vector::new(0.0, 8.0),
                blur_radius: 24.0,
            },
            ..Default::default()
        })
        .align_x(Horizontal::Center)
        .align_y(Vertical::Center);

    let protected = mouse_area(popup).on_press(Message::DoNothing);

    mouse_area(
        Container::new(protected)
            .width(Length::Fill)
            .height(Length::Fill)
            .style(|_theme| iced::widget::container::Style {
                background: Some(Background::Color(Color::from_rgba(0.0, 0.0, 0.0, 0.85))),
                ..Default::default()
            })
            .align_x(Horizontal::Center)
            .align_y(Vertical::Center),
    )
    .on_press(Message::ClosePopup)
    .into()
}

fn create_preview<'a>(app: &'a Papyrust, project: &'a Project) -> Element<'a, Message> {
    if let Some(file_name) = &project.meta.file {
        let video_path = format!("{}/{}", project.path, file_name);

        if let Some(video) = app.peek_video(&video_path) {
            let video_width = 720.0;
            let video_height = 405.0;

            Container::new(
                VideoPlayer::new(video)
                    .width(Length::Fixed(video_width))
                    .height(Length::Fixed(video_height)),
            )
            .width(Length::Fixed(video_width))
            .height(Length::Fixed(video_height))
            .style(|_theme| iced::widget::container::Style {
                background: Some(Background::Color(Color::from_rgba(0.0, 0.0, 0.0, 0.95))),
                border: Border {
                    radius: 12.0.into(),
                    width: 2.0,
                    color: Color::from_rgba(0.4, 0.4, 0.4, 0.5),
                },
                shadow: Shadow {
                    color: Color::from_rgba(0.0, 0.0, 0.0, 0.3),
                    offset: Vector::new(0.0, 4.0),
                    blur_radius: 12.0,
                },
                ..Default::default()
            })
            .align_x(Horizontal::Center)
            .align_y(Vertical::Center)
            .into()
        } else {
            let dots = match app.animation_state {
                0 => "Loading video.  ",
                1 => "Loading video.. ",
                2 => "Loading video...",
                _ => "Loading video   ",
            };

            let video_width = 720.0;
            let video_height = 405.0;

            Container::new(
                text(dots)
                    .size(18)
                    .style(|_theme| iced::widget::text::Style {
                        color: Some(Color::from_rgba(1.0, 1.0, 1.0, 0.8)),
                        ..Default::default()
                    }),
            )
            .width(Length::Fixed(video_width))
            .height(Length::Fixed(video_height))
            .style(|_theme| iced::widget::container::Style {
                background: Some(Background::Color(Color::from_rgba(0.15, 0.15, 0.15, 0.9))),
                border: Border {
                    radius: 12.0.into(),
                    width: 2.0,
                    color: Color::from_rgba(0.4, 0.4, 0.4, 0.5),
                },
                ..Default::default()
            })
            .align_x(Horizontal::Center)
            .align_y(Vertical::Center)
            .into()
        }
    } else {
        let video_width = 720.0;
        let video_height = 405.0;

        Container::new(text("No video available").size(18).style(|_theme| {
            iced::widget::text::Style {
                color: Some(Color::from_rgba(1.0, 1.0, 1.0, 0.8)),
                ..Default::default()
            }
        }))
        .width(Length::Fixed(video_width))
        .height(Length::Fixed(video_height))
        .style(|_theme| iced::widget::container::Style {
            background: Some(Background::Color(Color::from_rgba(0.15, 0.15, 0.15, 0.9))),
            border: Border {
                radius: 12.0.into(),
                width: 2.0,
                color: Color::from_rgba(0.4, 0.4, 0.4, 0.5),
            },
            ..Default::default()
        })
        .align_x(Horizontal::Center)
        .align_y(Vertical::Center)
        .into()
    }
}
</file>

<file path="src/ui/components/panel.rs">
use iced::{
    widget::{text, Button, Container, Row},
    Alignment, Element, Padding,
};

use crate::Message;

use crate::ui::state::Page;

pub fn build(_app: &crate::Papyrust) -> Element<Message> {
    let library = Button::new(text("Library"))
        .on_press(Message::SwitchPage(Page::Library))
        .padding(Padding::from([8, 16]));

    let discover = Button::new(text("Discover"))
        .on_press(Message::SwitchPage(Page::Discover))
        .padding(Padding::from([8, 16]));

    let content = Row::new()
        .push(library)
        .push(discover)
        .spacing(15)
        .align_y(Alignment::Center);

    Container::new(content)
        .padding(Padding::from([10, 20]))
        .into()
}
</file>

<file path="src/ui/loader/mod.rs">
use crate::ui::loader::project::{Project, ProjectMeta};
use std::{fs, path::PathBuf};

pub mod project;

const WALLPAPER_ENGINE_ID: &str = "431960";
const WORKSHOP_PATHS: [&str; 4] = [
    "~/.steam/steam/steamapps/workshop",
    "~/.local/share/Steam/steamapps/workshop",
    "~/.var/app/com.valvesoftware.Steam/.local/share/Steam/steamapps/workshop",
    "~/snap/steam/common/.local/share/Steam/steamapps/workshop",
];

fn resolve_paths() -> Vec<PathBuf> {
    WORKSHOP_PATHS
        .iter()
        .map(|p| shellexpand::tilde(p).to_string())
        .map(PathBuf::from)
        .filter(|p| p.exists())
        .map(|p| p.join("content").join(WALLPAPER_ENGINE_ID))
        .filter(|p| p.exists())
        .collect()
}

pub struct Loader {
    project_paths: Vec<PathBuf>,
    current: usize,
}

impl Loader {
    pub fn new() -> Self {
        let mut paths = Vec::new();

        for base in resolve_paths() {
            if let Ok(entries) = fs::read_dir(base) {
                for entry in entries.flatten() {
                    let dir = entry.path();
                    if dir.is_dir() && dir.join("project.json").exists() {
                        paths.push(dir);
                    }
                }
            }
        }

        Loader {
            project_paths: paths,
            current: 0,
        }
    }

    pub fn next(&mut self) -> Option<Result<Project, String>> {
        if self.current >= self.project_paths.len() {
            None
        } else {
            let dir = self.project_paths[self.current].clone();
            self.current += 1;
            let path = dir.join("project.json");
            Some(parse(&path, &dir))
        }
    }
}

fn parse(path: &PathBuf, dir: &PathBuf) -> Result<Project, String> {
    let content = fs::read_to_string(path)
        .map_err(|e| format!("Failed to read {}: {}", path.display(), e))?;

    let meta: ProjectMeta = serde_json::from_str(&content)
        .map_err(|e| format!("JSON parse error in {}: {}", path.display(), e))?;

    Ok(Project {
        meta,
        path: dir.to_string_lossy().to_string(),
    })
}
</file>

<file path="src/ui/loader/project.rs">
use serde::Deserialize;

#[derive(Deserialize, Debug, Clone, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum ProjectType {
    #[serde(alias = "Web")]
    Web,
    #[serde(alias = "Video")]
    Video,
    #[serde(alias = "Application")]
    Application,
    #[serde(alias = "Scene")]
    Scene,
}

#[derive(Deserialize, Debug, Clone)]
pub struct ProjectMeta {
    pub title: Option<String>,
    pub description: Option<String>,
    pub tags: Option<Vec<String>>,
    #[serde(rename = "type")]
    pub file_type: Option<ProjectType>,
    pub preview: Option<String>,
    pub file: Option<String>,
}

#[derive(Clone, Debug)]
pub struct Project {
    pub meta: ProjectMeta,
    pub path: String,
}
</file>

<file path="src/ui/pages/discover.rs">
use iced::Element;

use crate::{Message, Papyrust};

pub fn build(_app: &Papyrust) -> Element<Message> {
    iced::widget::text("Discover").into()
}
</file>

<file path="src/ui/pages/mod.rs">
pub mod discover;
pub mod library;
</file>

<file path="build.rs">
use gl_generator::{Api, Fallbacks, Profile, Registry};
use std::env;
use std::fs::File;
use std::path::Path;

fn main() {
    let dest = env::var("OUT_DIR").unwrap();
    let mut file = File::create(&Path::new(&dest).join("gl_bindings.rs")).unwrap();

    Registry::new(Api::Gles2, (3, 0), Profile::Core, Fallbacks::All, [])
        .write_bindings(gl_generator::GlobalGenerator, &mut file)
        .unwrap();
}
</file>

<file path="src/bin/daemon/utils.rs">
use std::thread;
use std::time::Duration;
use std::time::{SystemTime, UNIX_EPOCH};

pub fn get_time_millis() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap()
        .as_millis() as u64
}

pub fn sleep_millis(millis: u64) {
    if millis > 0 {
        thread::sleep(Duration::from_millis(millis));
    }
}

pub fn default_shader() -> &'static str {
    r#"
#ifdef GL_ES
precision highp float;
#endif

uniform sampler2D u_media;
uniform vec2 u_resolution;
uniform float u_time;

varying vec2 texCoords;

void main() {
    vec2 uv = texCoords;
    
    // High-quality scaling with subtle animation
    float scale = 1.0 + 0.005 * sin(u_time * 1.5);
    vec2 center = vec2(0.5);
    uv = (uv - center) * scale + center;
    
    // Ensure UV coordinates stay within bounds
    uv = clamp(uv, 0.0, 1.0);
    
    // Sample texture with high precision
    vec4 color = texture2D(u_media, uv);
    
    // Preserve original color fidelity
    gl_FragColor = color;
}
"#
}

pub fn vertex_shader() -> &'static str {
    r#"
#version 100
attribute highp vec2 datIn;
attribute highp vec2 texIn;
varying highp vec2 texCoords;

void main() {
    texCoords = texIn;
    gl_Position = vec4(datIn, 0.0, 1.0);
}
"#
}
</file>

<file path="src/ui/components/mod.rs">
pub mod lib_popup;
pub mod panel;
</file>

<file path="src/ui/pages/library.rs">
use iced::alignment::{Horizontal, Vertical};
use iced::widget::image::Handle;
use iced::widget::{Button, Column, Container};
use iced::{
    widget::{column, container, scrollable, text},
    Element, Length,
};
use iced::{Alignment, Padding, Task};
use image::{imageops, load_from_memory, RgbaImage};
use tokio::{fs, task};

use tracing::error;
use crate::ui::loader::project::{Project, ProjectType};
use crate::ui::loader::Loader;
use crate::{Message, Papyrust};

pub struct Library {
    pub projects: Vec<Project>,
    pub preview: Vec<Option<Handle>>,
}

const PREVIEW_WIDTH: f32 = 140.0;
const PREVIEW_HEIGHT: f32 = 140.0;

const ITEM_WIDTH: f32 = 160.0;
const ITEM_HEIGHT: f32 = 200.0;

impl Library {
    pub fn new() -> Self {
        let mut loader = Loader::new();
        let mut projects = Vec::new();
        let mut preview = Vec::new();

        while let Some(result) = loader.next() {
            match result {
                Ok(project) => {
                    // Skip for now all non-video projects
                    if project.meta.file_type != Some(ProjectType::Video) {
                        continue;
                    }
                    projects.push(project);
                    preview.push(None);
                }
                Err(e) => error!("Project parse error: {}", e),
            }
        }

        Self { projects, preview }
    }

    pub fn next(&mut self) -> Option<Task<Message>> {
        self.projects
            .iter()
            .enumerate()
            .find(|(idx, proj)| self.preview[*idx].is_none() && proj.meta.preview.is_some())
            .map(|(idx, proj)| {
                let name = proj.meta.preview.as_ref().unwrap().clone();
                let path = format!("{}/{}", proj.path, name);
                Task::perform(
                    async move {
                        let buf = fs::read(&path).await.ok();
                        if let Some(bytes) = buf {
                            let decode = task::spawn_blocking(move || {
                                let img = load_from_memory(&bytes).ok()?;
                                let mut rgba = img.to_rgba8();

                                // Ik this is not the most efficient way to handle this, but iced forces me to do it this way
                                rgba = Self::resize_image(rgba, PREVIEW_WIDTH as u32);
                                rgba = Self::round_image(rgba, 4.0);
                                let (w, h) = rgba.dimensions();
                                Some((w, h, rgba.into_raw()))
                            })
                            .await
                            .ok()
                            .flatten();

                            if let Some((w, h, pixels)) = decode {
                                return (idx, Ok((w, h, pixels)));
                            }
                        }
                        (idx, Err(()))
                    },
                    |(i, result)| match result {
                        Ok((w, h, pixels)) => Message::PreviewDecoded(i, w, h, pixels),
                        Err(_) => Message::PreviewError(i),
                    },
                )
            })
    }

    fn round_image(img: RgbaImage, radius: f32) -> RgbaImage {
        let (width, height) = img.dimensions();
        let mut rounded = img.clone();

        let radius_u32 = radius as u32;
        let right_bound = width.saturating_sub(radius_u32);
        let bottom_bound = height.saturating_sub(radius_u32);
        let radius_sq = radius * radius;

        let corners = [
            (0..radius_u32, 0..radius_u32),
            (right_bound..width, 0..radius_u32),
            (0..radius_u32, bottom_bound..height),
            (right_bound..width, bottom_bound..height),
        ];

        for (x_range, y_range) in corners {
            for y in y_range {
                for x in x_range.clone() {
                    let (dx, dy) = match (x < radius_u32, y < radius_u32) {
                        (true, true) => (radius - x as f32, radius - y as f32),
                        (false, true) => {
                            (x as f32 - (width as f32 - radius - 1.0), radius - y as f32)
                        }
                        (true, false) => {
                            (radius - x as f32, y as f32 - (height as f32 - radius - 1.0))
                        }
                        (false, false) => (
                            x as f32 - (width as f32 - radius - 1.0),
                            y as f32 - (height as f32 - radius - 1.0),
                        ),
                    };

                    if dx * dx + dy * dy > radius_sq {
                        rounded.get_pixel_mut(x, y)[3] = 0;
                    }
                }
            }
        }

        rounded
    }
    fn resize_image(img: RgbaImage, target_size: u32) -> RgbaImage {
        let (width, height) = img.dimensions();

        let scale = target_size as f32 / width.max(height) as f32;
        let new_width = (width as f32 * scale) as u32;
        let new_height = (height as f32 * scale) as u32;

        let src_image = fast_image_resize::images::Image::from_vec_u8(
            width,
            height,
            img.into_raw(),
            fast_image_resize::PixelType::U8x4,
        )
        .unwrap();

        let mut dst_image = fast_image_resize::images::Image::new(
            new_width,
            new_height,
            fast_image_resize::PixelType::U8x4,
        );

        let mut resizer = fast_image_resize::Resizer::new();

        let resize_options = fast_image_resize::ResizeOptions::new().resize_alg(
            fast_image_resize::ResizeAlg::Convolution(fast_image_resize::FilterType::Lanczos3),
        );

        resizer
            .resize(&src_image, &mut dst_image, Some(&resize_options))
            .unwrap();

        let resized_rgba =
            RgbaImage::from_raw(new_width, new_height, dst_image.into_vec()).unwrap();

        let crop_x = (new_width.saturating_sub(target_size)) / 2;
        let crop_y = (new_height.saturating_sub(target_size)) / 2;

        imageops::crop_imm(&resized_rgba, crop_x, crop_y, target_size, target_size).to_image()
    }
}

pub fn build(app: &Papyrust) -> Element<Message> {
    let lib = &app.library;
    let grid = crate::ui::view::create_grid(&app, &lib.projects, &lib.preview);

    container(scrollable(column![text("Library").size(30), grid]))
        .padding(20)
        .width(Length::Fill)
        .height(Length::Fill)
        .into()
}

pub fn render_item<'a>(
    app: &Papyrust,
    project: &'a Project,
    preview: Option<Handle>,
) -> Element<'a, Message> {
    let title = project.meta.title.as_deref().unwrap_or("Untitled");
    let preview = create_preview(app, preview, project);

    Button::new(
        Container::new(
            Column::new()
                .align_x(Alignment::Center)
                .padding(Padding::new(0.0).top(4.0))
                .push(preview)
                .push(
                    text(title)
                        .size(14)
                        .style(|_theme: &_| iced::widget::text::Style {
                            color: Some(iced::Color::WHITE),
                            ..Default::default()
                        })
                        .width(Length::Fixed(ITEM_WIDTH - 20.0))
                        .align_x(Alignment::Center),
                )
                .spacing(8),
        )
        .width(Length::Fixed(ITEM_WIDTH))
        .height(Length::Fixed(ITEM_HEIGHT)),
    )
    .width(Length::Fixed(ITEM_WIDTH))
    .height(Length::Fixed(ITEM_HEIGHT))
    .style(|_theme, status| {
        let base_color = iced::Color::from_rgba(0.0, 0.0, 0.0, 0.15);
        let hover_color = iced::Color::from_rgba(0.5, 0.5, 0.5, 0.3);
        let border_color = iced::Color::from_rgba(0.0, 0.0, 0.0, 0.2);

        match status {
            iced::widget::button::Status::Hovered => iced::widget::button::Style {
                background: Some(iced::Background::Color(hover_color)),
                border: iced::Border {
                    radius: 8.0.into(),
                    width: 1.0,
                    color: border_color,
                },
                shadow: iced::Shadow {
                    color: iced::Color::from_rgba(0.0, 0.0, 0.0, 0.1),
                    offset: iced::Vector::new(0.0, 2.0),
                    blur_radius: 4.0,
                },
                ..Default::default()
            },
            _ => iced::widget::button::Style {
                background: Some(iced::Background::Color(base_color)),
                border: iced::Border {
                    radius: 8.0.into(),
                    ..Default::default()
                },
                ..Default::default()
            },
        }
    })
    .on_press(Message::OpenPopup(project.clone()))
    .into()
}

fn create_preview<'a>(
    app: &Papyrust,
    preview: Option<Handle>,
    project: &'a Project,
) -> Element<'a, Message> {
    if let Some(handle) = preview {
        Container::new(
            iced::widget::image(handle)
                .width(Length::Fixed(PREVIEW_WIDTH))
                .height(Length::Fixed(PREVIEW_HEIGHT)),
        )
        .width(Length::Fixed(PREVIEW_WIDTH))
        .height(Length::Fixed(PREVIEW_HEIGHT))
        .clip(true)
        .into()
    } else if project.meta.preview.is_some() {
        let dots = match app.animation_state {
            0 => "Loading.  ",
            1 => "Loading.. ",
            2 => "Loading...",
            _ => "Loading   ",
        };

        Container::new(text(dots).style(|_theme: &_| iced::widget::text::Style {
            color: Some(iced::Color::from_rgba(1.0, 1.0, 1.0, 0.6)),
            ..Default::default()
        }))
        .width(Length::Fixed(PREVIEW_WIDTH))
        .height(Length::Fixed(PREVIEW_HEIGHT))
        .align_x(Horizontal::Center)
        .align_y(Vertical::Center)
        .style(|_theme| iced::widget::container::Style {
            background: Some(iced::Background::Color(iced::Color::from_rgba(
                0.5, 0.5, 0.5, 0.1,
            ))),
            border: iced::Border {
                radius: 4.0.into(),
                ..Default::default()
            },
            ..Default::default()
        })
        .into()
    } else {
        Container::new(
            text("No preview").style(|_theme: &_| iced::widget::text::Style {
                color: Some(iced::Color::from_rgba(1.0, 1.0, 1.0, 0.6)),
                ..Default::default()
            }),
        )
        .width(Length::Fixed(PREVIEW_WIDTH))
        .height(Length::Fixed(PREVIEW_HEIGHT))
        .align_x(Horizontal::Center)
        .align_y(Vertical::Center)
        .style(|_theme| iced::widget::container::Style {
            background: Some(iced::Background::Color(iced::Color::from_rgba(
                0.5, 0.5, 0.5, 0.1,
            ))),
            border: iced::Border {
                radius: 4.0.into(),
                ..Default::default()
            },
            ..Default::default()
        })
        .into()
    }
}
</file>

<file path="src/ui/ipc.rs">
use anyhow::Result;
use serde_json::json;
use std::io::{BufRead, BufReader, Write};
use std::os::unix::net::UnixStream;

use tracing::info;
const SOCKET_PATH: &str = "/tmp/papyrust-daemon.sock";

pub fn set_image(monitor: String, path: String, shader: Option<String>) -> Result<()> {
    let cmd = json!({
        "SetImage": {
            "path": path,
            "shader": shader,
            "monitor": monitor
        }
    });
    send_command(cmd)
}

pub fn set_video(monitor: String, path: String, shader: Option<String>) -> Result<()> {
    let cmd = json!({
        "SetVideo": {
            "path": path,
            "shader": shader,
            // "monitor": monitor
        }
    });
    send_command(cmd)
}

pub fn set_shader(monitor: String, path: String) -> Result<()> {
    let cmd = json!({
        "SetShader": {
            "path": path,
            "monitor": monitor
        }
    });
    send_command(cmd)
}


fn send_command(cmd: serde_json::Value) -> Result<()> {
    tracing::debug!(event = "ui_send_cmd", cmd = %cmd, "Sending IPC command");

    let mut stream = UnixStream::connect(SOCKET_PATH)?;
    writeln!(stream, "{}", cmd)?;
    stream.flush()?;

    let mut reader = BufReader::new(stream);
    let mut response = String::new();
    reader.read_line(&mut response)?;

    info!("{}", response.trim());
    tracing::debug!(event = "ui_recv_reply", reply = %response.trim(), "Received IPC reply");
    Ok(())
}
</file>

<file path=".gitignore">
/target
repomix-output.xml
flamegraph.svg
perf.data
perf.data.old
stacks.folded
</file>

<file path="src/bin/cli.rs">
use anyhow::Result;
use clap::{Parser, Subcommand};
use serde_json::json;
use std::io::{BufRead, BufReader, Write};
use std::os::unix::net::UnixStream;
use tracing_subscriber::{EnvFilter, fmt};

#[derive(Parser)]
#[command(name = "papyrust")]
#[command(about = "A small cli for papyrust-daemon")]
struct Args {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    Image {
        path: String,
        #[arg(long)]
        shader: Option<String>,
        #[arg(long)]
        monitor: Option<String>,
    },
    Video {
        path: String,
        #[arg(long)]
        shader: Option<String>,
        #[arg(long)]
        monitor: Option<String>,
        #[arg(long)]
        mute: bool,
    },
    Shader {
        path: String,
        #[arg(long)]
        monitor: Option<String>,
    },
}

fn main() -> Result<()> {
    let _ = fmt()
        .with_env_filter(
            EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new("off")),
        )
        .with_target(true)
        .compact()
        .try_init();
    let args = Args::parse();

    let mut stream = UnixStream::connect("/tmp/papyrust-daemon.sock")?;

    let command = match args.command {
        Commands::Image {
            path,
            shader,
            monitor,
        } => json!({
            "SetImage": {
                "path": path,
                "shader": shader,
                "monitor": monitor
            }
        }),
        Commands::Video {
            path,
            shader,
            monitor,
            mute,
        } => json!({
            "SetVideo": {
                "path": path,
                "shader": shader,
                "monitor": monitor,
                "mute": mute
            }
        }),
        Commands::Shader { path, monitor } => json!({
            "SetShader": {
                "path": path,
                "monitor": monitor
            }
        }),
    };

    writeln!(stream, "{}", command)?;
    stream.flush()?;

    let mut reader = BufReader::new(stream);
    let mut response = String::new();
    reader.read_line(&mut response)?;

    println!("{}", response.trim());
    Ok(())
}
</file>

<file path="src/ui/mod.rs">
pub mod components;
pub mod ipc;
pub mod loader;
pub mod pages;
pub mod state;
pub mod view;
</file>

<file path="src/bin/daemon/wayland/state.rs">
use tracing::{debug, info};
use std::collections::HashMap;
use wayland_client::protocol::{wl_compositor, wl_output, wl_region, wl_registry, wl_surface};
use wayland_client::{Connection, Dispatch, QueueHandle, Proxy};
use wayland_protocols::xdg::xdg_output::zv1::client::{zxdg_output_manager_v1, zxdg_output_v1};
use wayland_protocols_wlr::layer_shell::v1::client::{zwlr_layer_shell_v1, zwlr_layer_surface_v1};

#[derive(Debug, Clone)]
pub struct OutputInfo {
    pub output: wl_output::WlOutput,
    pub width: i32,
    pub height: i32,
    pub name: Option<String>,
    pub transform: wl_output::Transform,
    pub scale: i32,
    pub logical_width: Option<u32>,
    pub logical_height: Option<u32>,
}

pub struct AppState {
    pub outputs: HashMap<u32, OutputInfo>,
    pub compositor: Option<wl_compositor::WlCompositor>,
    pub layer_shell: Option<zwlr_layer_shell_v1::ZwlrLayerShellV1>,
    pub output_manager: Option<zxdg_output_manager_v1::ZxdgOutputManagerV1>,
    pub configured_count: usize,
    pub total_surfaces: usize,
    pub layer_surface_configs: HashMap<u32, (u32, u32)>,
    pub surface_to_output: HashMap<u32, String>,
}

impl AppState {
    pub fn new() -> Self {
        Self {
            outputs: HashMap::new(),
            compositor: None,
            layer_shell: None,
            output_manager: None,
            configured_count: 0,
            total_surfaces: 0,
            layer_surface_configs: HashMap::new(),
            surface_to_output: HashMap::new(),
        }
    }
}

impl Dispatch<wl_registry::WlRegistry, ()> for AppState {
    fn event(
        state: &mut Self,
        registry: &wl_registry::WlRegistry,
        event: wl_registry::Event,
        _: &(),
        _: &Connection,
        qh: &QueueHandle<AppState>,
    ) {
        match event {
            wl_registry::Event::Global {
                name,
                interface,
                version,
            } => {
                debug!("Global: {} {} {}", name, interface, version);
                match interface.as_str() {
                    "wl_output" => {
                        let output =
                            registry.bind::<wl_output::WlOutput, _, _>(name, version, qh, name);
                        state.outputs.insert(
                            name,
                            OutputInfo {
                                output,
                                width: 0,
                                height: 0,
                                name: None,
                                transform: wl_output::Transform::Normal,
                                scale: 1,
                                logical_width: None,
                                logical_height: None,
                            },
                        );
                    }
                    "wl_compositor" => {
                        state.compositor =
                            Some(registry.bind::<wl_compositor::WlCompositor, _, _>(
                                name,
                                version,
                                qh,
                                (),
                            ));
                    }
                    "zwlr_layer_shell_v1" => {
                        state.layer_shell = Some(
                            registry.bind::<zwlr_layer_shell_v1::ZwlrLayerShellV1, _, _>(
                                name,
                                version,
                                qh,
                                (),
                            ),
                        );
                    }
                    "zxdg_output_manager_v1" => {
                        state.output_manager = Some(
                            registry.bind::<zxdg_output_manager_v1::ZxdgOutputManagerV1, _, _>(
                                name,
                                version,
                                qh,
                                (),
                            ),
                        );
                    }
                    _ => {}
                }
            }
            wl_registry::Event::GlobalRemove { name } => {
                state.outputs.remove(&name);
            }
            _ => {}
        }
    }
}

impl Dispatch<wl_output::WlOutput, u32> for AppState {
    fn event(
        state: &mut Self,
        _: &wl_output::WlOutput,
        event: wl_output::Event,
        id: &u32,
        _: &Connection,
        _: &QueueHandle<AppState>,
    ) {
        if let Some(info) = state.outputs.get_mut(id) {
            match event {
                wl_output::Event::Geometry { transform, .. } => {
                    info.transform = transform
                        .into_result()
                        .unwrap_or(wl_output::Transform::Normal);
                }
                wl_output::Event::Scale { factor } => {
                    info.scale = factor;
                }
                wl_output::Event::Mode {
                    flags,
                    width,
                    height,
                    ..
                } => {
                    if let Ok(m) = flags.into_result() {
                        if m.contains(wl_output::Mode::Current) {
                            info.width = width;
                            info.height = height;
                        }
                    }
                }
                _ => {}
            }
        }
    }
}

impl Dispatch<zxdg_output_v1::ZxdgOutputV1, u32> for AppState {
    fn event(
        state: &mut Self,
        _: &zxdg_output_v1::ZxdgOutputV1,
        event: zxdg_output_v1::Event,
        output_id: &u32,
        _: &Connection,
        _: &QueueHandle<AppState>,
    ) {
        match event {
            zxdg_output_v1::Event::Name { name } => {
                if let Some(output_info) = state.outputs.get_mut(output_id) {
                    output_info.name = Some(name);
                }
            }
            zxdg_output_v1::Event::LogicalSize { width, height } => {
                if let Some(output_info) = state.outputs.get_mut(output_id) {
                    output_info.logical_width = Some(width as u32);
                    output_info.logical_height = Some(height as u32);
                    debug!("Output {} logical size: {}x{}", output_info.name.as_deref().unwrap_or("unknown"), width, height);
                }
            }
            _ => {}
        }
    }
}

impl Dispatch<zwlr_layer_surface_v1::ZwlrLayerSurfaceV1, Option<String>> for AppState {
    fn event(
        state: &mut Self,
        surface: &zwlr_layer_surface_v1::ZwlrLayerSurfaceV1,
        event: zwlr_layer_surface_v1::Event,
        output_name: &Option<String>,
        _: &Connection,
        _: &QueueHandle<AppState>,
    ) {
        match event {
            zwlr_layer_surface_v1::Event::Configure {
                serial,
                width,
                height,
            } => {
                surface.ack_configure(serial);
                let surface_id = surface.id().protocol_id();
                let output_name = output_name.clone().unwrap_or_else(|| format!("unknown-{}", surface_id));
                
                info!("Layer surface {} (output {}) configured: {}x{}", surface_id, output_name, width, height);
                
                state.layer_surface_configs.insert(surface_id, (width, height));
                state.surface_to_output.insert(surface_id, output_name);
                state.configured_count += 1;
            }
            _ => {}
        }
    }
}

impl Dispatch<wl_compositor::WlCompositor, ()> for AppState {
    fn event(
        _: &mut Self,
        _: &wl_compositor::WlCompositor,
        _: wl_compositor::Event,
        _: &(),
        _: &Connection,
        _: &QueueHandle<AppState>,
    ) {
    }
}

impl Dispatch<zwlr_layer_shell_v1::ZwlrLayerShellV1, ()> for AppState {
    fn event(
        _: &mut Self,
        _: &zwlr_layer_shell_v1::ZwlrLayerShellV1,
        _: zwlr_layer_shell_v1::Event,
        _: &(),
        _: &Connection,
        _: &QueueHandle<AppState>,
    ) {
    }
}

impl Dispatch<zxdg_output_manager_v1::ZxdgOutputManagerV1, ()> for AppState {
    fn event(
        _: &mut Self,
        _: &zxdg_output_manager_v1::ZxdgOutputManagerV1,
        _: zxdg_output_manager_v1::Event,
        _: &(),
        _: &Connection,
        _: &QueueHandle<AppState>,
    ) {
    }
}

impl Dispatch<wl_surface::WlSurface, ()> for AppState {
    fn event(
        _: &mut Self,
        _: &wl_surface::WlSurface,
        _: wl_surface::Event,
        _: &(),
        _: &Connection,
        _: &QueueHandle<AppState>,
    ) {
    }
}

impl Dispatch<wl_region::WlRegion, ()> for AppState {
    fn event(
        _: &mut Self,
        _: &wl_region::WlRegion,
        _: wl_region::Event,
        _: &(),
        _: &Connection,
        _: &QueueHandle<AppState>,
    ) {
    }
}
</file>

<file path="src/bin/daemon/ipc.rs">
use crate::media::MediaType;
use anyhow::{Result, anyhow};
use serde::{Deserialize, Serialize};
use std::io::{BufRead, BufReader, Write};
use std::os::unix::net::{UnixListener, UnixStream};
use std::sync::mpsc::Sender;
use std::thread;

#[derive(Debug, Serialize, Deserialize)]
pub enum IpcCommand {
    SetImage {
        path: String,
        shader: Option<String>,
        monitor: Option<String>,
    },
    SetVideo {
        path: String,
        shader: Option<String>,
        monitor: Option<String>,
        #[serde(default)]
        mute: bool,
    },
    SetShader {
        path: String,
        monitor: Option<String>,
    },
}

#[derive(Debug, Serialize, Deserialize)]
pub enum IpcResponse {
    Success,
    Error { message: String },
    Status { current_media: String },
}

#[derive(Debug, Clone)]
pub struct MediaChange {
    pub media_type: MediaType,
    pub monitor: Option<String>,
    pub mute: bool,
}

pub fn start_server(tx: Sender<MediaChange>) -> Result<()> {
    let socket_path = "/tmp/papyrust-daemon.sock";
    let _ = std::fs::remove_file(socket_path);

    let listener =
        UnixListener::bind(socket_path).map_err(|e| anyhow!("Failed to bind IPC socket: {}", e))?;

    tracing::info!(
        event = "ipc_listen",
        path = socket_path,
        "IPC server listening"
    );
    for stream in listener.incoming() {
        match stream {
            Ok(stream) => {
                let tx_clone = tx.clone();
                thread::spawn(move || {
                    if let Err(e) = handle_client(stream, tx_clone) {
                        tracing::warn!(event = "ipc_client_error", error = %e, "Client handling error");
                    }
                });
            }
            Err(e) => {
                tracing::warn!(event = "ipc_accept_error", error = %e, "IPC accept failed");
            }
        }
    }

    Ok(())
}

fn handle_client(stream: UnixStream, tx: Sender<MediaChange>) -> Result<()> {
    let peer = stream.peer_addr().ok();
    tracing::debug!(event = "ipc_client_begin", ?peer, "Client connected");

    let mut reader = BufReader::new(&stream);
    let mut writer = stream.try_clone()?;
    let mut line = String::new();

    while reader.read_line(&mut line)? > 0 {
        let trimmed = line.trim();
        let command: IpcCommand =
            serde_json::from_str(trimmed).map_err(|e| anyhow!("Invalid JSON command: {}", e))?;

        match &command {
            IpcCommand::SetImage { monitor, path, .. } => {
                tracing::info!(event = "ipc_command", cmd = "SetImage", monitor = monitor.as_deref(), path = %path, "Applying image");
            }
            IpcCommand::SetVideo {
                monitor,
                path,
                mute,
                ..
            } => {
                tracing::info!(event = "ipc_command", cmd = "SetVideo", monitor = monitor.as_deref(), path = %path, mute = *mute, "Applying video");
            }
            IpcCommand::SetShader { monitor, path } => {
                tracing::info!(event = "ipc_command", cmd = "SetShader", monitor = monitor.as_deref(), path = %path, "Applying shader");
            }
        }

        let response = match command {
            IpcCommand::SetImage {
                path,
                shader,
                monitor,
            } => {
                let media_change = MediaChange {
                    media_type: MediaType::Image { path, shader },
                    monitor,
                    mute: false,
                };
                match tx.send(media_change) {
                    Ok(_) => IpcResponse::Success,
                    Err(e) => IpcResponse::Error {
                        message: e.to_string(),
                    },
                }
            }
            IpcCommand::SetVideo {
                path,
                shader,
                monitor,
                mute,
            } => {
                let media_change = MediaChange {
                    media_type: MediaType::Video { path, shader },
                    monitor,
                    mute,
                };
                match tx.send(media_change) {
                    Ok(_) => IpcResponse::Success,
                    Err(e) => IpcResponse::Error {
                        message: e.to_string(),
                    },
                }
            }
            IpcCommand::SetShader { path, monitor } => {
                let media_change = MediaChange {
                    media_type: MediaType::Shader(path),
                    monitor,
                    mute: false,
                };
                match tx.send(media_change) {
                    Ok(_) => IpcResponse::Success,
                    Err(e) => IpcResponse::Error {
                        message: e.to_string(),
                    },
                }
            }
        };

        let response_json = serde_json::to_string(&response)?;
        writeln!(writer, "{}", response_json)?;
        writer.flush()?;

        tracing::debug!(event = "ipc_reply", response = %response_json, "Sent reply to client");
        line.clear();
    }

    tracing::debug!(event = "ipc_client_end", "Client disconnected");
    Ok(())
}
</file>

<file path="src/bin/daemon/wayland/monitors.rs">
use anyhow::{Result, anyhow};
use khronos_egl as egl;
use wayland_client::protocol::wl_compositor;
use wayland_client::{Connection, Proxy, QueueHandle};
use wayland_protocols_wlr::layer_shell::v1::client::{zwlr_layer_shell_v1, zwlr_layer_surface_v1};

use crate::media::MediaType;
use crate::wayland::renderer::MediaRenderer;
use crate::wayland::state::{AppState, OutputInfo};

pub struct MonitorState {
    pub egl_display: egl::Display,
    pub egl_surface: egl::Surface,
    pub egl_context: egl::Context,
    pub renderer: MediaRenderer,
    #[allow(dead_code)]
    pub output_info: OutputInfo,
    pub egl_window: wayland_egl::WlEglSurface,
    pub current_width: u32,
    pub current_height: u32,
    #[allow(dead_code)]
    pub layer_surface: zwlr_layer_surface_v1::ZwlrLayerSurfaceV1,
    pub layer_surface_id: u32,
    pub configured: bool,
    pub output_name: String,
}

pub fn create_monitor_state(
    output_info: &OutputInfo,
    compositor: &wl_compositor::WlCompositor,
    layer_shell: &zwlr_layer_shell_v1::ZwlrLayerShellV1,
    layer_name: Option<&str>,
    media_type: MediaType,
    egl_instance: &egl::Instance<egl::Static>,
    conn: &Connection,
    qh: &QueueHandle<AppState>,
    fps: u16,
) -> Result<MonitorState> {
    let surface = compositor.create_surface(qh, ());
    let input_region = compositor.create_region(qh, ());
    surface.set_input_region(Some(&input_region));

    let layer = match layer_name {
        Some("top") => zwlr_layer_shell_v1::Layer::Top,
        Some("bottom") => zwlr_layer_shell_v1::Layer::Bottom,
        Some("overlay") => zwlr_layer_shell_v1::Layer::Overlay,
        Some("background") | None => zwlr_layer_shell_v1::Layer::Background,
        _ => zwlr_layer_shell_v1::Layer::Background,
    };

    let layer_surface = layer_shell.get_layer_surface(
        &surface,
        Some(&output_info.output),
        layer,
        "papyrust-daemon".to_string(),
        qh,
        output_info.name.clone(),
    );

    let layer_surface_id = layer_surface.id().protocol_id();
    let output_name = output_info.name.clone().unwrap_or_else(|| format!("unknown-{}", layer_surface_id));

    tracing::info!(
        event = "layer_surface_create",
        output = %output_name,
        surface_id = layer_surface_id,
        layer = ?layer_name.unwrap_or("background"),
        "Created layer surface"
    );

    layer_surface.set_exclusive_zone(-1);
    layer_surface.set_anchor(
        zwlr_layer_surface_v1::Anchor::Top
            | zwlr_layer_surface_v1::Anchor::Left
            | zwlr_layer_surface_v1::Anchor::Right
            | zwlr_layer_surface_v1::Anchor::Bottom,
    );
    
    surface.commit();

    let display_ptr = conn.display().id().as_ptr();
    let egl_display = unsafe { egl_instance.get_display(display_ptr as *mut _) }
        .ok_or_else(|| anyhow!("Failed to get EGL display for Wayland connection"))?;
    let _version = egl_instance.initialize(egl_display)?;

    egl_instance.bind_api(egl::OPENGL_ES_API)?;

    let config_attribs = [
        egl::SURFACE_TYPE,
        egl::WINDOW_BIT,
        egl::RENDERABLE_TYPE,
        egl::OPENGL_ES2_BIT,
        egl::RED_SIZE,
        8,
        egl::GREEN_SIZE,
        8,
        egl::BLUE_SIZE,
        8,
        egl::ALPHA_SIZE,
        8,
        egl::NONE,
    ];

    let mut configs = Vec::with_capacity(1);
    egl_instance.choose_config(egl_display, &config_attribs, &mut configs)?;
    let config = configs
        .first()
        .ok_or_else(|| anyhow!("No suitable EGL config"))?;

    let context_attribs = [
        egl::CONTEXT_MAJOR_VERSION,
        2,
        egl::CONTEXT_MINOR_VERSION,
        0,
        egl::NONE,
    ];
    let context = egl_instance.create_context(egl_display, *config, None, &context_attribs)?;

    let initial_width = 100;
    let initial_height = 100;
    
    let egl_window =
        wayland_egl::WlEglSurface::new(surface.id(), initial_width, initial_height)
            .map_err(|e| anyhow!("Failed to create wl_egl_window: {e}"))?;

    let egl_surface = unsafe {
        egl_instance.create_window_surface(
            egl_display,
            *config,
            egl_window.ptr() as *mut _,
            Some(&[egl::NONE]),
        )?
    };

    egl_instance.make_current(
        egl_display,
        Some(egl_surface),
        Some(egl_surface),
        Some(context),
    )?;

    tracing::debug!(
        event = "egl_ready",
        output = %output_name,
        width = initial_width,
        height = initial_height,
        "EGL surface/context ready"
    );

    let renderer = MediaRenderer::new(media_type, fps)?;

    Ok(MonitorState {
        egl_display,
        egl_surface,
        egl_context: context,
        renderer,
        output_info: output_info.clone(),
        egl_window,
        current_width: initial_width as u32,
        current_height: initial_height as u32,
        layer_surface,
        layer_surface_id,
        configured: false,
        output_name,
    })
}

impl MonitorState {
    pub fn resize(&mut self, width: u32, height: u32) -> Result<()> {
        if self.current_width != width || self.current_height != height {
            tracing::info!(
                event = "monitor_resize",
                output = %self.output_name,
                surface_id = self.layer_surface_id,
                from_width = self.current_width,
                from_height = self.current_height,
                to_width = width,
                to_height = height,
                "Applying monitor resize"
            );
            self.egl_window.resize(width as i32, height as i32, 0, 0);
            self.current_width = width;
            self.current_height = height;
            self.configured = true;
        } else {
            tracing::debug!(
                event = "monitor_resize_skipped",
                output = %self.output_name,
                width,
                height,
                "Resize skipped (dimensions unchanged)"
            );
        }
        Ok(())
    }
}
</file>

<file path="src/bin/daemon/wayland/renderer.rs">
use crate::utils;
use crate::wayland::fifo::FifoReader;
use anyhow::{Result, anyhow};
use std::ffi::{CStr, CString};
use wayland_client::protocol::wl_output;

use crate::gl_bindings as gl;
use crate::media::{load_texture, MediaType, VideoDecoder, load_shader};
use crate::utils::{default_shader, vertex_shader};

pub struct MediaRenderer {
    shader: u32,
    texture: Option<u32>,
    decoder: Option<VideoDecoder>,
    vbo: u32,
    media_width: u32,
    media_height: u32,
    start_time: u64,
    media_type: MediaType,
    fps: u16,
}

impl MediaRenderer {
    pub fn new(media_type: MediaType, fps: u16) -> Result<Self> {
        tracing::info!(
            event = "renderer_create",
            ?media_type,
            fps,
            "Creating MediaRenderer"
        );

        let start_time = utils::get_time_millis();

        unsafe {
            gl::load_with(|s| {
                let c_str = CString::new(s).unwrap();
                let proc_addr = match CStr::from_bytes_with_nul(b"eglGetProcAddress\0") {
                    Ok(name) => libc::dlsym(libc::RTLD_DEFAULT, name.as_ptr()),
                    Err(_) => std::ptr::null_mut(),
                };
                if proc_addr.is_null() {
                    std::ptr::null()
                } else {
                    let get_proc_addr: extern "C" fn(*const i8) -> *const std::ffi::c_void =
                        std::mem::transmute(proc_addr);
                    get_proc_addr(c_str.as_ptr())
                }
            });

            gl::ClearColor(0.0, 0.0, 0.0, 1.0);
        }

        let (shader_program, media_texture, video_decoder, media_width, media_height) =
            if media_type == MediaType::Shader("default".to_string()) {
                let program = Self::default_shader()?;
                (program, None, None, 0, 0)
            } else {
                match &media_type {
                    MediaType::Shader(path) => {
                        let program = Self::create_pure_shader(path)?;
                        (program, None, None, 0, 0)
                    }
                    MediaType::Image { path, shader } => {
                        let img = image::open(path)
                            .map_err(|e| anyhow!("Failed to open image {}: {}", path, e))?;
                        let (w, h) = (img.width(), img.height());
                        let texture = load_texture(path)?;
                        let program = if let Some(s) = shader {
                            Self::create_media_shader(s)?
                        } else {
                            Self::create_default_shader()?
                        };
                        (program, Some(texture), None, w, h)
                    }
                    MediaType::Video { path, shader } => {
                        let decoder = if fps > 0 {
                            VideoDecoder::new_with_fps(path, Some(fps as f64))?
                        } else {
                            VideoDecoder::new(path)?
                        };
                        let (w, h) = (decoder.width(), decoder.height());
                        let texture = decoder.texture();
                        let program = if let Some(s) = shader {
                            Self::create_media_shader(s)?
                        } else {
                            Self::create_default_shader()?
                        };
                        (program, Some(texture), Some(decoder), w, h)
                    }
                }
            };

        let (vbo, _) = Self::setup_geometry()?;

        tracing::debug!(
            event = "renderer_ready",
            media_width,
            media_height,
            has_texture = media_texture.is_some(),
            has_decoder = video_decoder.is_some(),
            "Renderer initialized"
        );

        Ok(Self {
            shader: shader_program,
            texture: media_texture,
            decoder: video_decoder,
            media_width,
            media_height,
            vbo,
            start_time,
            media_type,
            fps,
        })
    }

    pub fn has_new_frame(&self) -> bool {
        if let Some(ref decoder) = self.decoder {
            decoder.has_new_frame()
        } else {
            false
        }
    }

    fn update_geometry(&self, output_width: i32, output_height: i32) {
        let output_w = output_width as f32;
        let output_h = output_height as f32;
        let media_w = self.media_width as f32;
        let media_h = self.media_height as f32;

        if media_w <= 0.0 || media_h <= 0.0 {
            // Default fullscreen quad when no media dimensions
            let verts: [f32; 16] = [
                -1.0, 1.0, 0.0, 0.0, 
                -1.0, -1.0, 0.0, 1.0, 
                1.0, -1.0, 1.0, 1.0, 
                1.0, 1.0, 1.0, 0.0,
            ];

            unsafe {
                gl::BindBuffer(gl::ARRAY_BUFFER, self.vbo);
                gl::BufferData(
                    gl::ARRAY_BUFFER,
                    (verts.len() * std::mem::size_of::<f32>()) as isize,
                    verts.as_ptr() as *const _,
                    gl::STATIC_DRAW,
                );
            }
            return;
        }

        // Calculate scaling to fill the entire screen (crop to fit)
        let media_aspect = media_w / media_h;
        let output_aspect = output_w / output_h;
        
        let (scale_x, scale_y) = if media_aspect > output_aspect {
            // Media is wider - scale to fill height, crop width
            let scale = output_h / media_h;
            let scaled_width = media_w * scale;
            let overflow = (scaled_width - output_w) / output_w;
            (1.0 + overflow, 1.0)
        } else {
            // Media is taller - scale to fill width, crop height
            let scale = output_w / media_w;
            let scaled_height = media_h * scale;
            let overflow = (scaled_height - output_h) / output_h;
            (1.0, 1.0 + overflow)
        };

        // Create fullscreen quad with proper texture coordinates for cropping
        let u_min = (1.0 - 1.0 / scale_x) * 0.5;
        let u_max = 1.0 - u_min;
        let v_min = (1.0 - 1.0 / scale_y) * 0.5;
        let v_max = 1.0 - v_min;

        let verts: [f32; 16] = [
            -1.0, 1.0, u_min, v_min,  // Top-left
            -1.0, -1.0, u_min, v_max, // Bottom-left  
            1.0, -1.0, u_max, v_max,  // Bottom-right
            1.0, 1.0, u_max, v_min,   // Top-right
        ];

        unsafe {
            gl::BindBuffer(gl::ARRAY_BUFFER, self.vbo);
            gl::BufferData(
                gl::ARRAY_BUFFER,
                (verts.len() * std::mem::size_of::<f32>()) as isize,
                verts.as_ptr() as *const _,
                gl::STATIC_DRAW,
            );
        }

        tracing::debug!(
            event = "geometry_updated",
            media_w, media_h, output_w, output_h,
            scale_x, scale_y,
            u_range = format!("{:.3}-{:.3}", u_min, u_max),
            v_range = format!("{:.3}-{:.3}", v_min, v_max),
            "Updated geometry for fullscreen scaling"
        );
    }

    fn default_shader() -> Result<u32> {
        let vert_source = r#"
            #version 100
            attribute highp vec2 datIn;
            attribute highp vec2 texIn;
            varying highp vec2 texCoords;
            void main() {
                texCoords = texIn;
                gl_Position = vec4(datIn, 0.0, 1.0);
            }
        "#;

        let frag_source = r#"
            #ifdef GL_ES
            precision mediump float;
            #endif
            void main() {
                gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0);
            }
        "#;

        Self::compile(vert_source, frag_source)
    }

    pub fn update_media(&mut self, new_media_type: MediaType, fps: u16) -> Result<()> {
        tracing::info!(
            event = "renderer_media_update",
            ?new_media_type,
            fps,
            "Updating renderer media"
        );

        if let Some(texture) = self.texture {
            unsafe {
                gl::DeleteTextures(1, &texture);
            }
            tracing::debug!(event = "texture_deleted", "Previous texture deleted");
        }
        self.decoder = None;

        let (shader_program, media_texture, video_decoder, media_width, media_height) =
            match &new_media_type {
                MediaType::Shader(path) => {
                    let program = Self::create_pure_shader(path)?;
                    (program, None, None, 0, 0)
                }
                MediaType::Image { path, shader } => {
                    let img = image::open(path)
                        .map_err(|e| anyhow!("Failed to open image {}: {}", path, e))?;
                    let (w, h) = (img.width(), img.height());
                    let texture = load_texture(path)?;
                    let program = if let Some(s) = shader {
                        Self::create_media_shader(s)?
                    } else {
                        Self::create_default_shader()?
                    };
                    (program, Some(texture), None, w, h)
                }
                MediaType::Video { path, shader } => {
                    let decoder = if fps > 0 {
                        VideoDecoder::new_with_fps(path, Some(fps as f64))?
                    } else {
                        VideoDecoder::new(path)?
                    };
                    let (w, h) = (decoder.width(), decoder.height());
                    let texture = decoder.texture();
                    let program = if let Some(s) = shader {
                        Self::create_media_shader(s)?
                    } else {
                        Self::create_default_shader()?
                    };
                    (program, Some(texture), Some(decoder), w, h)
                }
            };

        unsafe {
            gl::DeleteProgram(self.shader);
        }

        self.shader = shader_program;
        self.texture = media_texture;
        self.decoder = video_decoder;
        self.media_width = media_width;
        self.media_height = media_height;
        self.media_type = new_media_type;
        self.fps = fps;

        tracing::debug!(
            event = "renderer_media_ready",
            media_width = self.media_width,
            media_height = self.media_height,
            has_decoder = self.decoder.is_some(),
            "Media update complete"
        );
        Ok(())
    }

    fn create_pure_shader(shader_path: &str) -> Result<u32> {
        let raw = load_shader(shader_path)?;
        let mut version_directive: Option<&str> = None;
        let mut body_lines = Vec::new();
        for line in raw.lines() {
            let trimmed = line.trim_start();
            if version_directive.is_none() && trimmed.starts_with("#version") {
                version_directive = Some(line);
            } else {
                body_lines.push(line);
            }
        }
        body_lines.retain(|l| {
            let t = l.trim_start();
            !(t.starts_with("precision ") && t.ends_with("float;"))
        });
        let mut frag_source = String::new();
        if let Some(v) = version_directive {
            frag_source.push_str(v);
            frag_source.push('\n');
        }
        frag_source.push_str(
            r#"
            #ifdef GL_ES
              #ifdef GL_FRAGMENT_PRECISION_HIGH
                precision highp float;
              #else
                precision mediump float;
              #endif
            #endif
            "#,
        );
        frag_source.push_str(&body_lines.join("\n"));
        let vert_source = r#"
            #version 100
            attribute highp vec2 datIn;
            attribute highp vec2 texIn;
            varying highp vec2 texCoords;
            void main() {
                texCoords = texIn;
                gl_Position = vec4(datIn, 0.0, 1.0);
            }
        "#;
        Self::compile(vert_source, &frag_source)
    }

    fn create_media_shader(shader_path: &str) -> Result<u32> {
        let raw = load_shader(shader_path)?;
        let mut version_directive: Option<&str> = None;
        let mut body_lines = Vec::new();
        for line in raw.lines() {
            let trimmed = line.trim_start();
            if version_directive.is_none() && trimmed.starts_with("#version") {
                version_directive = Some(line);
            } else {
                body_lines.push(line);
            }
        }
        body_lines.retain(|l| {
            let t = l.trim_start();
            !(t.starts_with("precision ") && t.ends_with("float;"))
        });
        let mut frag_source = String::new();
        if let Some(v) = version_directive {
            frag_source.push_str(v);
            frag_source.push('\n');
        }
        frag_source.push_str(
            r#"
            #ifdef GL_ES
              #ifdef GL_FRAGMENT_PRECISION_HIGH
                precision highp float;
              #else
                precision mediump float;
              #endif
            #endif
            "#,
        );
        frag_source.push_str(&body_lines.join("\n"));
        let vert_source = vertex_shader();
        Self::compile(vert_source, &frag_source)
    }

    fn create_default_shader() -> Result<u32> {
        let vert_source = vertex_shader();
        let frag_source = default_shader();
        Self::compile(vert_source, frag_source)
    }

    fn compile(vert_source: &str, frag_source: &str) -> Result<u32> {
        unsafe {
            let program = gl::CreateProgram();

            let vert_shader = gl::CreateShader(gl::VERTEX_SHADER);
            let vert_c_str = CString::new(vert_source)?;
            gl::ShaderSource(vert_shader, 1, &vert_c_str.as_ptr(), std::ptr::null());
            gl::CompileShader(vert_shader);
            Self::check_compile(vert_shader, "vertex")?;

            let frag_shader = gl::CreateShader(gl::FRAGMENT_SHADER);
            let frag_c_str = CString::new(frag_source)?;
            gl::ShaderSource(frag_shader, 1, &frag_c_str.as_ptr(), std::ptr::null());
            gl::CompileShader(frag_shader);
            Self::check_compile(frag_shader, "fragment")?;

            gl::AttachShader(program, vert_shader);
            gl::AttachShader(program, frag_shader);
            gl::LinkProgram(program);
            Self::check_linked(program)?;

            gl::DeleteShader(vert_shader);
            gl::DeleteShader(frag_shader);

            Ok(program)
        }
    }

    fn check_compile(shader: u32, shader_type: &str) -> Result<()> {
        unsafe {
            let mut status = 0;
            gl::GetShaderiv(shader, gl::COMPILE_STATUS, &mut status);
            if status == gl::FALSE as i32 {
                let mut log_length = 0;
                gl::GetShaderiv(shader, gl::INFO_LOG_LENGTH, &mut log_length);
                let mut log = vec![0u8; log_length as usize];
                gl::GetShaderInfoLog(
                    shader,
                    log_length,
                    std::ptr::null_mut(),
                    log.as_mut_ptr() as *mut i8,
                );
                let log_str = CStr::from_ptr(log.as_ptr() as *const i8).to_string_lossy();
                return Err(anyhow!(
                    "{} shader compilation failed: {}",
                    shader_type,
                    log_str
                ));
            }
        }
        Ok(())
    }

    fn check_linked(program: u32) -> Result<()> {
        unsafe {
            let mut status = 0;
            gl::GetProgramiv(program, gl::LINK_STATUS, &mut status);
            if status == gl::FALSE as i32 {
                let mut log_length = 0;
                gl::GetProgramiv(program, gl::INFO_LOG_LENGTH, &mut log_length);
                let mut log = vec![0u8; log_length as usize];
                gl::GetProgramInfoLog(
                    program,
                    log_length,
                    std::ptr::null_mut(),
                    log.as_mut_ptr() as *mut i8,
                );
                let log_str = CStr::from_ptr(log.as_ptr() as *const i8).to_string_lossy();
                return Err(anyhow!("Program linking failed: {}", log_str));
            }
        }
        Ok(())
    }

    fn setup_geometry() -> Result<(u32, u32)> {
        let vertices: [f32; 16] = [
            -1.0, 1.0, 0.0, 0.0, 
            -1.0, -1.0, 0.0, 1.0, 
            1.0, -1.0, 1.0, 1.0, 
            1.0, 1.0, 1.0, 0.0,
        ];

        let indices: [u32; 6] = [0, 1, 2, 2, 3, 0];

        unsafe {
            let mut vbo = 0;
            gl::GenBuffers(1, &mut vbo);
            gl::BindBuffer(gl::ARRAY_BUFFER, vbo);
            gl::BufferData(
                gl::ARRAY_BUFFER,
                (vertices.len() * std::mem::size_of::<f32>()) as isize,
                vertices.as_ptr() as *const _,
                gl::STATIC_DRAW,
            );

            let mut ebo = 0;
            gl::GenBuffers(1, &mut ebo);
            gl::BindBuffer(gl::ELEMENT_ARRAY_BUFFER, ebo);
            gl::BufferData(
                gl::ELEMENT_ARRAY_BUFFER,
                (indices.len() * std::mem::size_of::<u32>()) as isize,
                indices.as_ptr() as *const _,
                gl::STATIC_DRAW,
            );

            gl::VertexAttribPointer(
                0,
                2,
                gl::FLOAT,
                gl::FALSE,
                4 * std::mem::size_of::<f32>() as i32,
                std::ptr::null(),
            );
            gl::EnableVertexAttribArray(0);

            gl::VertexAttribPointer(
                1,
                2,
                gl::FLOAT,
                gl::FALSE,
                4 * std::mem::size_of::<f32>() as i32,
                (2 * std::mem::size_of::<f32>()) as *const _,
            );
            gl::EnableVertexAttribArray(1);

            Ok((vbo, ebo))
        }
    }

    pub fn draw(
        &mut self,
        fifo_reader: &mut Option<FifoReader>,
        output_width: i32,
        output_height: i32,
        _transform: wl_output::Transform,
    ) -> Result<()> {
        unsafe {
            gl::UseProgram(self.shader);
            gl::Clear(gl::COLOR_BUFFER_BIT);
            gl::Viewport(0, 0, output_width, output_height);

            if let Some(ref mut decoder) = self.decoder {
                let _ = decoder.update_frame()?;
            }

            let time_loc = gl::GetUniformLocation(self.shader, b"time\0".as_ptr() as *const i8);
            if time_loc != -1 {
                let time = (utils::get_time_millis() - self.start_time) as f32 / 1000.0;
                gl::Uniform1f(time_loc, time);
            }

            let resolution_loc =
                gl::GetUniformLocation(self.shader, b"resolution\0".as_ptr() as *const i8);
            if resolution_loc != -1 {
                gl::Uniform2f(resolution_loc, output_width as f32, output_height as f32);
            }

            if let Some(texture) = self.texture {
                gl::ActiveTexture(gl::TEXTURE0);
                gl::BindTexture(gl::TEXTURE_2D, texture);

                let media_loc =
                    gl::GetUniformLocation(self.shader, b"u_media\0".as_ptr() as *const i8);
                if media_loc != -1 {
                    gl::Uniform1i(media_loc, 0);
                }
            }

            if let Some(reader) = fifo_reader {
                let fifo_loc = gl::GetUniformLocation(self.shader, b"fifo\0".as_ptr() as *const i8);
                if fifo_loc != -1 {
                    if let Ok(Some(sample)) = reader.read_sample() {
                        let left_val = if !sample.left.is_empty() {
                            sample.left[0] as f32
                        } else {
                            0.0
                        };
                        let right_val = if !sample.right.is_empty() {
                            sample.right[0] as f32
                        } else {
                            0.0
                        };
                        gl::Uniform2f(fifo_loc, right_val, left_val);
                    }
                }
            }

            self.update_geometry(output_width, output_height);
            gl::DrawElements(gl::TRIANGLES, 6, gl::UNSIGNED_INT, std::ptr::null());
        }
        Ok(())
    }
}
</file>

<file path="src/bin/daemon/wayland/mod.rs">
use crate::utils;
use crate::wayland::fifo::FifoReader;
use crate::wayland::monitors::create_monitor_state;
use crate::wayland::state::AppState;
use anyhow::{Result, anyhow};
use khronos_egl as egl;
use std::collections::HashMap;
use std::process::Child;
use std::sync::mpsc::Receiver;
use wayland_client::{Connection, protocol::wl_output};

use crate::ipc::MediaChange;
use crate::media::MediaType;
use crate::lossless_scaling::ScalingAlgorithm;

mod fifo;
mod monitors;
mod renderer;
mod state;

pub fn init(
    media_type: MediaType,
    fps: u16,
    layer_name: Option<&str>,
    fifo_path: Option<&str>,
    ipc_receiver: Receiver<MediaChange>,
    mute: bool,
    _scaling_algorithm: Option<ScalingAlgorithm>,
    _sharpening: f32,
) -> Result<()> {
    tracing::info!(
        event = "wayland_init",
        fps,
        layer = layer_name,
        fifo = fifo_path,
        mute,
        scaling = ?_scaling_algorithm,
        sharpening = _sharpening,
        "Initializing Wayland stack with lossless scaling"
    );

    let conn = Connection::connect_to_env()?;
    let mut event_queue = conn.new_event_queue();
    let qh = event_queue.handle();
    let mut app_state = AppState::new();
    let _registry = conn.display().get_registry(&qh, ());
    event_queue.roundtrip(&mut app_state)?;

    if let Some(ref om) = app_state.output_manager {
        for (id, info) in &app_state.outputs {
            om.get_xdg_output(&info.output, &qh, *id);
        }
    }
    event_queue.roundtrip(&mut app_state)?;

    let compositor = app_state
        .compositor
        .as_ref()
        .ok_or_else(|| anyhow!("Compositor not available"))?;
    let layer_shell = app_state
        .layer_shell
        .as_ref()
        .ok_or_else(|| anyhow!("Layer shell not available"))?;
    let egl_instance = egl::Instance::new(egl::Static);
    let mut monitor_states = HashMap::new();

    for output_info in app_state.outputs.values() {
        if let Some(name) = &output_info.name {
            let ms = create_monitor_state(
                output_info,
                compositor,
                layer_shell,
                layer_name,
                media_type.clone(),
                &egl_instance,
                &conn,
                &qh,
                fps,
            )?;
            monitor_states.insert(name.clone(), ms);
            app_state.total_surfaces += 1;
        }
    }

    event_queue.roundtrip(&mut app_state)?;
    while app_state.configured_count < app_state.total_surfaces {
        tracing::debug!(
            event = "waiting_layer_config",
            configured = app_state.configured_count,
            total = app_state.total_surfaces,
            "Awaiting layer surface configuration"
        );
        event_queue.blocking_dispatch(&mut app_state)?;
    }
    event_queue.roundtrip(&mut app_state)?;

    for ms in monitor_states.values_mut() {
        if let Some((width, height)) = app_state.layer_surface_configs.get(&ms.layer_surface_id) {
            tracing::info!(
                event = "monitor_configured",
                output = %ms.output_name,
                width, height,
                "Applying initial layer surface config"
            );
            ms.resize(*width, *height)?;
        } else {
            tracing::error!(
                event = "monitor_no_config",
                output = %ms.output_name,
                "No layer surface config found for monitor"
            );
        }
    }

    let mut has_video = matches!(media_type, MediaType::Video { .. });
    for ms in monitor_states.values() {
        if has_video {
            egl_instance.swap_interval(ms.egl_display, 1)?;
            tracing::debug!(
                event = "swap_interval_set",
                output = %ms.output_name,
                interval = 1,
                "Swap interval set for video playback"
            );
        } else {
            let interval = if fps == 0 { 1 } else { 0 };
            egl_instance.swap_interval(ms.egl_display, interval)?;
            tracing::debug!(
                event = "swap_interval_set",
                output = %ms.output_name,
                interval,
                "Swap interval set"
            );
        }
    }

    let mut fifo_reader = fifo_path.map(FifoReader::new).transpose()?;
    tracing::info!(
        event = "render_loop_start",
        monitors = monitor_states.len(),
        "Starting render loop"
    );

    let mut last_audio_path: Option<String> = None;
    let mut last_audio_child: Option<Child> = None;
    let mut frame_count = 0u64;
    let mut last_fps_check = utils::get_time_millis();

    let target_frame_time = if fps > 0 { 1000 / fps as u64 } else { 16 };

    loop {
        let frame_start = utils::get_time_millis();

        event_queue.dispatch_pending(&mut app_state)?;
        for ms in monitor_states.values_mut() {
            if let Some((width, height)) = app_state.layer_surface_configs.get(&ms.layer_surface_id)
            {
                if !ms.configured || ms.current_width != *width || ms.current_height != *height {
                    if let Some(config_output) =
                        app_state.surface_to_output.get(&ms.layer_surface_id)
                    {
                        if config_output == &ms.output_name {
                            ms.resize(*width, *height)?;
                        }
                    }
                }
            }
        }

        if let Ok(media_change) = ipc_receiver.try_recv() {
            let new_has_video = matches!(media_change.media_type, MediaType::Video { .. });
            if has_video != new_has_video {
                has_video = new_has_video;
                for ms in monitor_states.values() {
                    if has_video {
                        egl_instance.swap_interval(ms.egl_display, 1)?;
                    } else {
                        egl_instance.swap_interval(ms.egl_display, if fps == 0 { 1 } else { 0 })?;
                    }
                }
                tracing::info!(
                    event = "swap_interval_reconfigured",
                    has_video,
                    "Reconfigured swap intervals due to media type change"
                );
            }

            if let MediaType::Video { path, .. } = &media_change.media_type {
                let effective_mute = mute || media_change.mute;

                if effective_mute || last_audio_path.as_deref() != Some(path.as_str()) {
                    if let Some(mut child) = last_audio_child.take() {
                        let _ = child.kill();
                        let _ = child.wait();
                        tracing::debug!(event = "audio_player_stopped", "Stopped ffplay");
                    }
                }

                if !effective_mute && last_audio_path.as_deref() != Some(path.as_str()) {
                    let audio_path = path.clone();
                    match std::process::Command::new("ffplay")
                        .args(&[
                            "-nodisp",
                            "-autoexit",
                            "-hide_banner",
                            "-loglevel",
                            "error",
                            "-loop",
                            "0",
                            &audio_path,
                        ])
                        .spawn()
                    {
                        Ok(child) => {
                            last_audio_child = Some(child);
                            last_audio_path = Some(path.clone());
                            tracing::info!(event = "audio_player_started", path = %audio_path, "Started ffplay for audio");
                        }
                        Err(e) => {
                            tracing::warn!(event = "audio_player_fail", error = %e, path = %audio_path, "Failed to start ffplay");
                        }
                    }
                } else if effective_mute {
                    last_audio_path = None;
                }
            } else {
                if let Some(mut child) = last_audio_child.take() {
                    let _ = child.kill();
                    let _ = child.wait();
                    tracing::debug!(
                        event = "audio_player_stopped",
                        "Stopped ffplay due to non-video media"
                    );
                }
                last_audio_path = None;
            }

            if let Some(target) = &media_change.monitor {
                if let Some(ms) = monitor_states.get_mut(target) {
                    egl_instance.make_current(
                        ms.egl_display,
                        Some(ms.egl_surface),
                        Some(ms.egl_surface),
                        Some(ms.egl_context),
                    )?;
                    tracing::info!(event = "media_update", output = %ms.output_name, "Updating media on single target");
                    ms.renderer.update_media(media_change.media_type, fps)?;
                }
            } else {
                tracing::info!(event = "media_update_all", "Updating media on all monitors");
                for ms in monitor_states.values_mut() {
                    egl_instance.make_current(
                        ms.egl_display,
                        Some(ms.egl_surface),
                        Some(ms.egl_surface),
                        Some(ms.egl_context),
                    )?;
                    ms.renderer
                        .update_media(media_change.media_type.clone(), fps)?;
                }
            }
        }

        // Render all outputs
        let mut any_video_updated = false;
        for ms in monitor_states.values_mut() {
            egl_instance.make_current(
                ms.egl_display,
                Some(ms.egl_surface),
                Some(ms.egl_surface),
                Some(ms.egl_context),
            )?;
            if ms.renderer.has_new_frame() {
                any_video_updated = true;
            }
            ms.renderer.draw(
                &mut fifo_reader,
                ms.current_width as i32,
                ms.current_height as i32,
                wl_output::Transform::Normal,
            )?;
            egl_instance.swap_buffers(ms.egl_display, ms.egl_surface)?;
        }

        frame_count += 1;

        if has_video {
            if fps == 0 {
                let elapsed = utils::get_time_millis() - frame_start;
                let target_frame_time = if any_video_updated { 16 } else { 33 };
                if elapsed < target_frame_time {
                    utils::sleep_millis(target_frame_time - elapsed);
                }
            } else {
                let elapsed = utils::get_time_millis() - frame_start;
                if elapsed < target_frame_time {
                    utils::sleep_millis(target_frame_time - elapsed);
                }
            }
        } else {
            let elapsed = utils::get_time_millis() - frame_start;
            let adaptive_frame_time = if any_video_updated {
                target_frame_time
            } else {
                target_frame_time * 2
            };
            if elapsed < adaptive_frame_time {
                utils::sleep_millis(adaptive_frame_time - elapsed);
            }
        }
        if frame_count % 300 == 0 {
            let now = utils::get_time_millis();
            let _fps_actual = 300000 / (now - last_fps_check + 1);
            last_fps_check = now;
        }
    }
}
</file>

<file path="src/bin/daemon/main.rs">
use anyhow::Result;
use clap::{Parser, ValueEnum};
use std::{process, sync::mpsc, thread};

use tracing_log::LogTracer;
use tracing_subscriber::{fmt, EnvFilter};

mod ipc;
mod media;
mod wayland;
mod utils;
mod lossless_scaling; // Add this line


mod gl_bindings {
    include!(concat!(env!("OUT_DIR"), "/gl_bindings.rs"));
}

#[derive(ValueEnum, Clone, Debug)]
enum Layer {
    Bottom,
    Top,
    Overlay,
    Background,
}

impl std::fmt::Display for Layer {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let s = match self {
            Layer::Bottom => "bottom",
            Layer::Top => "top",
            Layer::Overlay => "overlay",
            Layer::Background => "background",
        };
        write!(f, "{}", s)
    }
}

#[derive(ValueEnum, Clone, Debug)]
enum ScalingMode {
    FSR,
    Lanczos,
    Mitchell,
    Bicubic,
    None,
}

#[derive(Parser, Debug)]
#[command(
    name = "papyrust-daemon",
    version = "0.1.0",
    about = "A Wayland wallpaper daemon with OpenGL ES shader support and lossless scaling"
)]
struct Args {
    #[arg(short = 'F', long)]
    fork: bool,

    #[arg(short, long, default_value = "60")]
    fps: u16,

    #[arg(short, long)]
    layer: Option<Layer>,

    #[arg(short = 'M', long)]
    fifo: Option<String>,

    #[arg(long, alias = "no-audio")]
    mute: bool,

    #[arg(short = 's', long, default_value = "fsr")]
    scaling: ScalingMode,

    #[arg(long, default_value = "0.3")]
    sharpening: f32,
}

fn main() -> Result<()> {
    let _ = LogTracer::init();
    let filter = EnvFilter::try_from_default_env()
        .unwrap_or_else(|_| EnvFilter::new("papyrust=info,wayland_client=warn"));
    let _ = fmt()
        .with_env_filter(filter)
        .with_target(true)
        .compact()
        .try_init();

    let args = Args::parse();

    tracing::info!(
        event = "daemon_start",
        fork = args.fork,
        fps = args.fps,
        layer = args.layer.as_ref().map(|l| l.to_string()),
        fifo = args.fifo.as_deref(),
        mute = args.mute,
        scaling = ?args.scaling,
        sharpening = args.sharpening,
        "Starting Papyrust daemon with lossless scaling"
    );

    if args.fork {
        unsafe {
            let pid = libc::fork();
            if pid > 0 {
                process::exit(0);
            }
            if pid == 0 {
                libc::close(0);
                libc::close(1);
                libc::close(2);
                tracing::debug!(event = "daemon_forked", "Detached from controlling terminal");
            }
        }
    }

    let (tx, rx) = mpsc::channel();

    let ipc_tx = tx.clone();
    thread::spawn(move || {
        if let Err(e) = ipc::start_server(ipc_tx) {
            tracing::error!(event = "ipc_server_error", error = %e, "IPC server error");
        }
    });

    let init_media = media::MediaType::Shader("default".to_string());

    let scaling_algorithm = match args.scaling {
        ScalingMode::FSR => Some(lossless_scaling::ScalingAlgorithm::FSR),
        ScalingMode::Lanczos => Some(lossless_scaling::ScalingAlgorithm::Lanczos),
        ScalingMode::Mitchell => Some(lossless_scaling::ScalingAlgorithm::Mitchell),
        ScalingMode::Bicubic => Some(lossless_scaling::ScalingAlgorithm::Bicubic),
        ScalingMode::None => None,
    };

    wayland::init(
        init_media,
        args.fps,
        args.layer.as_ref().map(|l| l.to_string()).as_deref(),
        args.fifo.as_deref(),
        rx,
        args.mute,
        scaling_algorithm,
        args.sharpening,
    )?;

    tracing::info!(event = "daemon_exit", "Papyrust daemon exited");
    Ok(())
}
</file>

<file path="src/bin/daemon/media.rs">
use anyhow::{Result, anyhow};
use ffmpeg_next as ffmpeg;
use std::fs::File;
use std::io::Read;
use std::path::Path;
use std::sync::{Arc, OnceLock};

use crate::gl_bindings as gl;
use crate::lossless_scaling::{LosslessScaler, ScalingAlgorithm};

#[derive(Debug, Clone, PartialEq)]
pub enum MediaType {
    Shader(String),
    Image {
        path: String,
        shader: Option<String>,
    },
    Video {
        path: String,
        shader: Option<String>,
    },
}

pub struct ImageLoader {
    _scaler: Option<Arc<LosslessScaler>>,
}

impl ImageLoader {
    pub fn new() -> Self {
        Self { _scaler: None }
    }

    #[allow(dead_code)]
    pub async fn new_with_scaler(algorithm: ScalingAlgorithm) -> Result<Self> {
        let scaler = LosslessScaler::new(algorithm).await?;
        Ok(Self {
            _scaler: Some(Arc::new(scaler)),
        })
    }

    pub fn load_texture(&self, path: &str) -> Result<u32> {
        tracing::info!(event = "image_load", path = %path, "Loading image");

        let img = image::open(path).map_err(|e| anyhow!("Failed to load image {}: {}", path, e))?;
        let rgba = img.to_rgba8();
        let (width, height) = (img.width(), img.height());

        tracing::debug!(event = "image_info", width, height, "Image decoded");

        let mut texture = 0;
        unsafe {
            gl::GenTextures(1, &mut texture);
            gl::BindTexture(gl::TEXTURE_2D, texture);
            
            // Set pixel alignment for better quality
            gl::PixelStorei(gl::UNPACK_ALIGNMENT, 4);
            
            // High-quality texture parameters
            gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_WRAP_S, gl::CLAMP_TO_EDGE as i32);
            gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_WRAP_T, gl::CLAMP_TO_EDGE as i32);
            
            // Use high-quality filtering
            gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_MIN_FILTER, gl::LINEAR_MIPMAP_LINEAR as i32);
            gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_MAG_FILTER, gl::LINEAR as i32);
            
            // Enable anisotropic filtering if available
            let mut max_anisotropy = 0.0f32;
            gl::GetFloatv(0x84FE, &mut max_anisotropy); // GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT
            if max_anisotropy > 1.0 {
                let anisotropy = max_anisotropy.min(16.0); // Cap at 16x
                gl::TexParameterf(gl::TEXTURE_2D, 0x84FE, anisotropy); // GL_TEXTURE_MAX_ANISOTROPY_EXT
                tracing::debug!(event = "anisotropic_filtering", anisotropy, "Applied anisotropic filtering");
            }
            
            gl::TexImage2D(
                gl::TEXTURE_2D,
                0,
                gl::RGBA as i32,
                width as i32,
                height as i32,
                0,
                gl::RGBA,
                gl::UNSIGNED_BYTE,
                rgba.as_ptr() as *const _,
            );
            
            // Generate mipmaps for better quality at different scales
            gl::GenerateMipmap(gl::TEXTURE_2D);
            
            tracing::debug!(event = "texture_created", width, height, texture, "High-quality texture created with mipmaps");
        }

        Ok(texture)
    }

    #[allow(dead_code)]
    pub fn load_texture_scaled(&self, path: &str, target_width: u32, target_height: u32, sharpening: f32) -> Result<u32> {
        if let Some(ref scaler) = self._scaler {
            tracing::info!(
                event = "image_load_scaled", 
                path = %path, 
                target_width, 
                target_height,
                sharpening,
                "Loading and scaling image with lossless algorithm"
            );

            let img = image::open(path).map_err(|e| anyhow!("Failed to load image {}: {}", path, e))?;
            let rgba = img.to_rgba8();
            let (orig_width, orig_height) = (img.width(), img.height());

            // Only scale if necessary
            let final_data = if orig_width != target_width || orig_height != target_height {
                let scaled_data = scaler.scale_texture(
                    &rgba,
                    orig_width,
                    orig_height,
                    target_width,
                    target_height,
                    sharpening,
                )?;
                scaled_data
            } else {
                rgba.into_raw()
            };

            let mut texture = 0;
            unsafe {
                gl::GenTextures(1, &mut texture);
                gl::BindTexture(gl::TEXTURE_2D, texture);
                gl::PixelStorei(gl::UNPACK_ALIGNMENT, 4);
                
                gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_WRAP_S, gl::CLAMP_TO_EDGE as i32);
                gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_WRAP_T, gl::CLAMP_TO_EDGE as i32);
                gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_MIN_FILTER, gl::LINEAR as i32);
                gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_MAG_FILTER, gl::LINEAR as i32);
                
                gl::TexImage2D(
                    gl::TEXTURE_2D,
                    0,
                    gl::RGBA as i32,
                    target_width as i32,
                    target_height as i32,
                    0,
                    gl::RGBA,
                    gl::UNSIGNED_BYTE,
                    final_data.as_ptr() as *const _,
                );
            }

            tracing::debug!(
                event = "scaled_texture_created", 
                orig_width, orig_height,
                target_width, target_height,
                texture,
                "Lossless scaled texture created"
            );

            Ok(texture)
        } else {
            self.load_texture(path)
        }
    }
}

pub struct VideoDecoder {
    decoder: ffmpeg::decoder::Video,
    scaler: Option<ffmpeg::software::scaling::Context>,
    texture: u32,
    _width: u32,
    _height: u32,
    input_ctx: ffmpeg::format::context::Input,
    stream_index: usize,
    video_path: String,
    last_frame_updated: bool,
    _time_base: f64,
    _video_start_time: f64,
    _playback_start_time: f64,
    forced_fps: Option<f64>,
    frame_count: u64,
    last_forced_frame_time: f64,
    current_frame: Option<ffmpeg::frame::Video>,
    next_frame: Option<ffmpeg::frame::Video>,
    reached_eof: bool,
    _video_fps: f64,
    _video_duration: f64,
    loop_count: u64,
    _lossless_scaler: Option<Arc<LosslessScaler>>,
}

impl VideoDecoder {
    pub fn new(path: &str) -> Result<Self> {
        Self::new_with_fps(path, None)
    }

    pub fn new_with_fps(path: &str, forced_fps: Option<f64>) -> Result<Self> {
        Self::new_with_scaler(path, forced_fps, None)
    }

    #[allow(dead_code)]
    pub async fn new_with_lossless_scaling(path: &str, forced_fps: Option<f64>, algorithm: ScalingAlgorithm) -> Result<Self> {
        let scaler = LosslessScaler::new(algorithm).await?;
        Self::new_with_scaler(path, forced_fps, Some(Arc::new(scaler)))
    }

    fn new_with_scaler(path: &str, forced_fps: Option<f64>, lossless_scaler: Option<Arc<LosslessScaler>>) -> Result<Self> {
        let fps_msg = if let Some(fps) = forced_fps {
            format!("forced FPS: {:.1}", fps)
        } else {
            "original timing".to_string()
        };
        tracing::info!(event = "video_open", path = %path, %fps_msg, has_lossless = lossless_scaler.is_some(), "Initializing video decoder");

        ffmpeg::init().map_err(|e| anyhow!("Failed to initialize FFmpeg: {}", e))?;
        let input_ctx = ffmpeg::format::input(&Path::new(path))
            .map_err(|e| anyhow!("Failed to open video file {}: {}", path, e))?;

        let stream = input_ctx
            .streams()
            .best(ffmpeg::media::Type::Video)
            .ok_or_else(|| anyhow!("No video stream found in {}", path))?;
        let stream_index = stream.index();

        let context_decoder = ffmpeg::codec::context::Context::from_parameters(stream.parameters())
            .map_err(|e| anyhow!("Failed to create codec context: {}", e))?;
        let decoder = context_decoder
            .decoder()
            .video()
            .map_err(|e| anyhow!("Failed to create video decoder: {}", e))?;

        let width = decoder.width();
        let height = decoder.height();

        let time_base = {
            let tb = stream.time_base();
            tb.0 as f64 / tb.1 as f64
        };

        let video_start_time = {
            let start = stream.start_time();
            if start != ffmpeg::ffi::AV_NOPTS_VALUE {
                start as f64 * time_base
            } else {
                0.0
            }
        };

        let video_duration = {
            let duration = stream.duration();
            if duration != ffmpeg::ffi::AV_NOPTS_VALUE {
                duration as f64 * time_base
            } else {
                let format_duration = input_ctx.duration();
                if format_duration != ffmpeg::ffi::AV_NOPTS_VALUE {
                    format_duration as f64 / ffmpeg::ffi::AV_TIME_BASE as f64
                } else {
                    0.0
                }
            }
        };

        let video_fps = {
            let rate = stream.rate();
            let fps = if rate.1 > 0 {
                rate.0 as f64 / rate.1 as f64
            } else {
                let avg_rate = stream.avg_frame_rate();
                if avg_rate.1 > 0 {
                    avg_rate.0 as f64 / avg_rate.1 as f64
                } else {
                    1.0 / time_base
                }
            };
            if (0.1..=240.0).contains(&fps) {
                fps
            } else {
                tracing::warn!(
                    event = "video_unusual_fps",
                    fps,
                    "Unusual FPS; using time base"
                );
                1.0 / time_base
            }
        };

        tracing::info!(
            event = "video_info",
            width,
            height,
            fps = video_fps,
            forced_fps,
            duration = video_duration,
            frame_duration = 1.0 / video_fps,
            "Video stream initialized"
        );

        let scaler = if decoder.format() != ffmpeg::format::Pixel::RGBA {
            Some(
                ffmpeg::software::scaling::Context::get(
                    decoder.format(),
                    width,
                    height,
                    ffmpeg::format::Pixel::RGBA,
                    width,
                    height,
                    ffmpeg::software::scaling::flag::Flags::LANCZOS, // Use higher quality scaling
                )
                .map_err(|e| anyhow!("Failed to create scaler: {}", e))?,
            )
        } else {
            None
        };

        let mut texture = 0;
        unsafe {
            gl::GenTextures(1, &mut texture);
            gl::BindTexture(gl::TEXTURE_2D, texture);
            gl::PixelStorei(gl::UNPACK_ALIGNMENT, 1);
            
            // High-quality texture parameters for video
            gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_WRAP_S, gl::CLAMP_TO_EDGE as i32);
            gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_WRAP_T, gl::CLAMP_TO_EDGE as i32);
            gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_MIN_FILTER, gl::LINEAR as i32);
            gl::TexParameteri(gl::TEXTURE_2D, gl::TEXTURE_MAG_FILTER, gl::LINEAR as i32);
            
            gl::TexImage2D(
                gl::TEXTURE_2D,
                0,
                gl::RGBA as i32,
                width as i32,
                height as i32,
                0,
                gl::RGBA,
                gl::UNSIGNED_BYTE,
                std::ptr::null(),
            );
        }

        Ok(Self {
            decoder,
            scaler,
            texture,
            _width: width,
            _height: height,
            input_ctx,
            stream_index,
            video_path: path.to_string(),
            last_frame_updated: false,
            _time_base: time_base,
            _video_start_time: video_start_time,
            _playback_start_time: crate::utils::get_time_millis() as f64 / 1000.0,
            forced_fps,
            frame_count: 0,
            last_forced_frame_time: crate::utils::get_time_millis() as f64 / 1000.0,
            current_frame: None,
            next_frame: None,
            reached_eof: false,
            _video_fps: video_fps,
            _video_duration: video_duration,
            loop_count: 0,
            _lossless_scaler: lossless_scaler,
        })
    }

    pub fn update_frame(&mut self) -> Result<bool> {
        self.last_frame_updated = false;
        let current_time = crate::utils::get_time_millis() as f64 / 1000.0;

        if let Some(forced_fps) = self.forced_fps {
            let min_frame_duration = 1.0 / forced_fps;
            let elapsed = current_time - self.last_forced_frame_time;

            if elapsed < min_frame_duration {
                return Ok(false);
            }

            self.last_forced_frame_time = current_time;
        }

        if self.current_frame.is_some() {
            if self.next_frame.is_some() {
                self.current_frame = self.next_frame.take();
                self.upload_current_frame();
                self.last_frame_updated = true;
                self.frame_count += 1;

                self.decode_next_frame()?;
                return Ok(self.last_frame_updated);
            } else {
                self.decode_next_frame()?;
                return Ok(self.last_frame_updated);
            }
        } else {
            self.decode_next_frame()?;
            if self.next_frame.is_some() {
                self.current_frame = self.next_frame.take();
                self.upload_current_frame();
                self.last_frame_updated = true;
                self.frame_count += 1;
                return Ok(true);
            }
        }

        Ok(false)
    }

    fn decode_next_frame(&mut self) -> Result<()> {
        if !self.decode_frame_to_buffer()? {
            self.loop_count += 1;
            tracing::debug!(
                event = "video_loop",
                loop_count = self.loop_count,
                "Video restarted for loop"
            );
            self.restart_video()?;
            self.decode_frame_to_buffer()?;
        }
        Ok(())
    }

    fn decode_frame_to_buffer(&mut self) -> Result<bool> {
        if self.reached_eof {
            return Ok(false);
        }

        for (stream, packet) in self.input_ctx.packets() {
            if stream.index() != self.stream_index {
                continue;
            }

            match self.decoder.send_packet(&packet) {
                Ok(_) => {
                    let mut decoded = ffmpeg::frame::Video::empty();
                    while self.decoder.receive_frame(&mut decoded).is_ok() {
                        let rgba_frame = self.convert_frame(decoded)?;
                        self.next_frame = Some(rgba_frame);
                        return Ok(true);
                    }
                }
                Err(ffmpeg::Error::Eof) => {
                    self.reached_eof = true;
                    return Ok(false);
                }
                Err(_) => {
                    continue;
                }
            }
        }

        self.reached_eof = true;
        Ok(false)
    }

    fn convert_frame(&mut self, frame: ffmpeg::frame::Video) -> Result<ffmpeg::frame::Video> {
        if frame.format() != ffmpeg::format::Pixel::RGBA {
            if let Some(ref mut scaler) = self.scaler {
                let mut rgba_frame = ffmpeg::frame::Video::empty();
                scaler
                    .run(&frame, &mut rgba_frame)
                    .map_err(|e| anyhow!("Scaling failed: {}", e))?;
                rgba_frame.set_pts(frame.pts());
                Ok(rgba_frame)
            } else {
                Ok(frame)
            }
        } else {
            Ok(frame)
        }
    }

    fn upload_current_frame(&self) {
        if let Some(ref frame) = self.current_frame {
            self.upload_frame(frame);
        }
    }

    fn upload_frame(&self, frame: &ffmpeg::frame::Video) {
        unsafe {
            gl::BindTexture(gl::TEXTURE_2D, self.texture);
            gl::PixelStorei(gl::UNPACK_ALIGNMENT, 1);
            gl::TexSubImage2D(
                gl::TEXTURE_2D,
                0,
                0,
                0,
                frame.width() as i32,
                frame.height() as i32,
                gl::RGBA,
                gl::UNSIGNED_BYTE,
                frame.data(0).as_ptr() as *const _,
            );
        }
    }

    fn restart_video(&mut self) -> Result<()> {
        self.current_frame = None;
        self.next_frame = None;
        self.reached_eof = false;

        self.input_ctx = ffmpeg::format::input(&Path::new(&self.video_path))
            .map_err(|e| anyhow!("Failed to re-open video {}: {}", self.video_path, e))?;

        let stream = self
            .input_ctx
            .streams()
            .best(ffmpeg::media::Type::Video)
            .ok_or_else(|| anyhow!("No video stream on restart"))?;

        self.stream_index = stream.index();

        let context_decoder =
            ffmpeg::codec::context::Context::from_parameters(stream.parameters())?;
        self.decoder = context_decoder.decoder().video()?;

        Ok(())
    }

    #[allow(dead_code)]
    pub fn scale_frame_with_lossless(&self, frame_data: &[u8], target_width: u32, target_height: u32, sharpening: f32) -> Result<Vec<u8>> {
        if let Some(ref scaler) = self._lossless_scaler {
            scaler.scale_texture(
                frame_data,
                self._width,
                self._height,
                target_width,
                target_height,
                sharpening,
            )
        } else {
            Ok(frame_data.to_vec())
        }
    }

    pub fn texture(&self) -> u32 {
        self.texture
    }

    pub fn width(&self) -> u32 {
        self._width
    }

    pub fn height(&self) -> u32 {
        self._height
    }

    pub fn has_new_frame(&self) -> bool {
        self.last_frame_updated
    }
}

// Thread-safe ImageLoader instance using OnceLock
static IMAGE_LOADER: OnceLock<ImageLoader> = OnceLock::new();

fn get_image_loader() -> &'static ImageLoader {
    IMAGE_LOADER.get_or_init(|| ImageLoader::new())
}

pub fn load_texture(path: &str) -> Result<u32> {
    get_image_loader().load_texture(path)
}

pub fn load_shader(path: &str) -> Result<String> {
    let mut file =
        File::open(path).map_err(|e| anyhow!("Failed to open shader file {}: {}", path, e))?;
    let mut source = String::new();
    file.read_to_string(&mut source)
        .map_err(|e| anyhow!("Failed to read shader file {}: {}", path, e))?;
    Ok(source)
}
</file>

<file path="src/ui/view.rs">
use iced::{
    alignment::{Horizontal, Vertical},
    widget::{image::Handle, Column, Container, Stack},
    Element, Length, Padding,
};
use iced_aw::Wrap;

use crate::{ui::loader::project::Project, Message, Papyrust};

use super::{components::lib_popup, components::panel, pages::discover, pages::library, state};

pub fn build(app: &Papyrust) -> Element<Message> {
    let content = match app.current_page {
        state::Page::Discover => discover::build(app),
        state::Page::Library => library::build(app),
    };

    let main = Column::new()
        .push(content)
        .width(Length::Fill)
        .height(Length::Fill);

    let panel = Container::new(panel::build(app))
        .width(Length::Fill)
        .height(Length::Fill)
        .padding(Padding {
            top: 0.0,
            right: 20.0,
            bottom: 0.0,
            left: 0.0,
        })
        .align_x(Horizontal::Center)
        .align_y(Vertical::Bottom);

    let main_content = Column::new().push(main).push(
        Container::new(panel)
            .width(Length::Fill)
            .height(Length::Fixed(80.0)),
    );

    if let Some(ref project) = app.popup_state {
        Stack::new()
            .push(main_content)
            .push(lib_popup::build(app, project))
            .into()
    } else {
        main_content.into()
    }
}

pub fn create_grid<'a>(
    app: &'a Papyrust,
    projects: &'a [Project],
    preview: &'a [Option<Handle>],
) -> Element<'a, Message> {
    let mut items = Vec::new();

    for (idx, project) in projects.iter().enumerate() {
        let handle = preview.get(idx).and_then(Clone::clone);
        items.push(library::render_item(app, project, handle));
    }

    Container::new(Wrap::with_elements(items).spacing(8.0).line_spacing(8.0))
        .width(Length::Fill)
        .padding(8)
        .into()
}
</file>

<file path="src/ui/state.rs">
use iced::{widget::image::Handle, Task};

use tracing::error;
use crate::{Message, Papyrust};

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Page {
    Discover,
    Library,
}

impl Default for Page {
    fn default() -> Self {
        Page::Library
    }
}

pub fn update(app: &mut Papyrust, message: Message) -> Task<Message> {
    match message {
        Message::SwitchPage(page) => {
            app.current_page = page;
            if page == Page::Library {
                return app.library.next().unwrap_or_else(Task::none);
            }
            Task::none()
        }
        Message::PreviewDecoded(idx, w, h, pixels) => {
            let handle = Handle::from_rgba(w, h, pixels);
            app.library.preview[idx] = Some(handle);
            app.library.next().unwrap_or_else(Task::none)
        }
        Message::PreviewError(_idx) => app.library.next().unwrap_or_else(Task::none),
        Message::Tick => {
            app.tick();
            Task::none()
        }
        Message::OpenPopup(project) => {
            app.popup_state = Some(project.clone());

            if let Some(file_name) = &project.meta.file {
                let video_path = format!("{}/{}", project.path, file_name);
                if app.should_load(&video_path) {
                    return Papyrust::load_video_async(video_path);
                }
            }
            Task::none()
        }
        Message::ClosePopup => {
            for video in app.videos.values_mut() {
                video.set_paused(true);
            }
            app.popup_state = None;
            Task::none()
        }
        Message::ApplyProject(project) => {
            if let Some(popup) = &app.popup_state {
                if popup.path == project.path {
                    app.popup_state = Some(project.clone());
                }
            } else {
                app.popup_state = Some(project.clone());
            }

            if let Some(file_name) = &project.meta.file {
                let video_path = format!("{}/{}", project.path, file_name);
                crate::ui::ipc::set_video("DP-2".to_string(), video_path, None).unwrap_or_else(
                    |e| {
                        error!("Failed to set video: {}", e);
                    },
                );
            }
            Task::none()
        }
        Message::LoadVideo(path) => {
            app.load_video(&path);
            Task::none()
        }
        Message::VideoLoaded(path) => {
            app.load_video(&path);
            Task::none()
        }
        Message::VideoError(path, error) => {
            error!("Failed to load video {}: {}", path, error);
            Task::none()
        }
        Message::DoNothing => Task::none(),
    }
}
</file>

<file path="Cargo.toml">
[package]
name = "papyrust"
version = "0.1.0"
edition = "2024"

[dependencies]
derive = "1.0.0"
fast_image_resize = { version = "5.1.4", features = ["image"] }
futures = "0.3.31"
iced = { version = "0.13.1", features = ["advanced", "image", "tokio"] }
iced_aw = { version = "0.12.2", features = ["wrap"] }
iced_video_player = { git = "https://github.com/jazzfool/iced_video_player" }
image = "0.25.6"
serde = { version = "1.0.219", features = ["derive"] }
serde_json = "1.0.140"
shellexpand = "3.1.1"
tokio = { version = "1.45.1", features = ["fs"] }
url = "2.5.4"

clap = { version = "4.4", features = ["derive"] }
wayland-client = "0.31"
wayland-protocols = { version = "0.31", features = ["client", "unstable"] }
wayland-protocols-wlr = { version = "0.2", features = ["client"] }
wayland-egl = "0.32"
khronos-egl = { version = "6.0", features = ["static"] }
gl = "0.14"
libc = "0.2"
anyhow = "1.0"
ffmpeg-next = "7.1.0"

wgpu = "0.20"
bytemuck = { version = "1.16", features = ["derive"] }
pollster = "0.3"

tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
tracing-log = "0.2"

[build-dependencies]
gl_generator = "0.14"

[profile.release]
debug = true

[profile.dev]
debug = true
opt-level = 0
overflow-checks = true

[lints.rust]
unsafe_op_in_unsafe_fn = "allow"

[[bin]]
name = "papyrust-daemon"
path = "src/bin/daemon/main.rs"

[[bin]]
name = "papyrust-cli"
path = "src/bin/cli.rs"

[[bin]]
name = "papyrust"
path = "src/main.rs"
</file>

<file path="src/main.rs">
use std::collections::HashMap;

use iced::{Element, Font, Settings, Subscription, Task};
use iced_video_player::Video;
use ui::state;

mod ui;

use ui::pages::library::Library;
use ui::{state::Page, view};

use crate::ui::loader::project::Project;

pub struct Papyrust {
    pub current_page: Page,
    pub library: Library,
    pub animation_state: usize,
    pub popup_state: Option<Project>,
    pub videos: HashMap<String, Video>,
}

#[derive(Debug, Clone)]
pub enum Message {
    SwitchPage(Page),
    PreviewDecoded(usize, u32, u32, Vec<u8>),
    PreviewError(usize),
    OpenPopup(Project),
    ClosePopup,
    ApplyProject(Project),
    Tick,
    LoadVideo(String),
    VideoLoaded(String),
    VideoError(String, String),
    DoNothing,
}

const _FIRA_BYTES: &[u8] = include_bytes!("../fonts/FiraCodeNerdFontMono-Regular.ttf");
const _UNIFONT_BYTES: &[u8] = include_bytes!("../fonts/unifont.ttf");

const _FIRA: Font = Font::with_name("FiraCode Nerd Font Mono Reg");
const _UNIFONT: Font = Font::with_name("Unifont");

impl Papyrust {
    fn new() -> (Self, Task<Message>) {
        let mut library = Library::new();
        let first = library.next().unwrap_or_else(Task::none);
        (
            Papyrust {
                current_page: Page::default(),
                library,
                animation_state: 0,
                popup_state: None,
                videos: HashMap::new(),
            },
            first,
        )
    }

    pub fn load_video(&mut self, path: &str) -> Option<&Video> {
        if !self.videos.contains_key(path) {
            if let Ok(url) = url::Url::parse(&format!("file://{}", path)) {
                if let Ok(video) = Video::new(&url) {
                    self.videos.insert(path.to_string(), video);
                }
            }
        }
        self.videos.get(path)
    }

    pub fn load_video_async(path: String) -> Task<Message> {
        Task::perform(
            async move {
                match url::Url::parse(&format!("file://{}", path)) {
                    Ok(url) => match tokio::task::spawn_blocking(move || Video::new(&url)).await {
                        Ok(Ok(_)) => Message::VideoLoaded(path),
                        Ok(Err(e)) => Message::VideoError(path, e.to_string()),
                        Err(e) => Message::VideoError(path, format!("Task error: {}", e)),
                    },
                    Err(e) => Message::VideoError(path, format!("Invalid URL: {}", e)),
                }
            },
            |msg| msg,
        )
    }

    pub fn peek_video(&self, path: &str) -> Option<&Video> {
        self.videos.get(path)
    }

    pub fn should_load(&self, path: &str) -> bool {
        !self.videos.contains_key(path)
    }

    pub fn tick(&mut self) {
        self.animation_state = (self.animation_state + 1) % 4;
    }

    fn update(&mut self, message: Message) -> Task<Message> {
        state::update(self, message)
    }

    fn view(&self) -> Element<Message> {
        view::build(self)
    }

    fn subscription(&self) -> Subscription<Message> {
        iced::time::every(std::time::Duration::from_millis(300)).map(|_| Message::Tick)
    }
}


fn main() -> iced::Result {
    let _ = tracing_log::LogTracer::init();
    let filter = tracing_subscriber::EnvFilter::try_from_default_env()
        .unwrap_or_else(|_| tracing_subscriber::EnvFilter::new("papyrust=info"));
    let _ = tracing_subscriber::fmt()
        .with_env_filter(filter)
        .with_target(true)
        .compact()
        .try_init();

    iced::application("Papyrust", Papyrust::update, Papyrust::view)
        .settings(Settings {
            default_font: Font::MONOSPACE,
            ..Default::default()
        })
        .subscription(Papyrust::subscription)
        .theme(|_| iced::theme::Theme::GruvboxDark)
        .run_with(Papyrust::new)
}
</file>

</files>
